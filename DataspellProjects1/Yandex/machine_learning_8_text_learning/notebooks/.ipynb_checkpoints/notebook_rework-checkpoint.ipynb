{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Привет, меня зовут Артем Хуршудов. Сегодня я проверю твой проект.\n",
    "<br> Дальнейшее общение будет происходить на \"ты\" если это не вызывает никаких проблем.\n",
    "<br> Желательно реагировать на каждый мой комментарий ('исправил', 'не понятно как исправить ошибку', ...)\n",
    "<br> Пожалуйста, не удаляй комментарии ревьюера, так как они повышают качество повторного ревью.\n",
    "\n",
    "Комментарии будут в <font color='green'>зеленой</font>, <font color='blue'>синей</font> или <font color='red'>красной</font> рамках:\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Если все сделано отлично\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Если можно немного улучшить\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка:</b> Если требуются исправления. Работа не может быть принята с красными комментариями.\n",
    "</div>\n",
    "\n",
    "-------------------\n",
    "\n",
    "Будет очень хорошо, если ты будешь помечать свои действия следующим образом:\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента:</b> ...\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Изменения:</b> Были внесены следующие изменения ...\n",
    "</div>\n",
    "\n",
    "<font color='green'><b>Полезные (и просто интересные) материалы:</b></font> \\\n",
    "Для работы с текстами используют и другие подходы. Например, сейчас активно используются RNN (LSTM) и трансформеры (BERT и другие с улицы Сезам, например, ELMO). НО! Они не являются панацеей, не всегда они нужны, так как и TF-IDF или Word2Vec + модели из классического ML тоже могут справляться. \\\n",
    "BERT тяжелый, существует много его вариаций для разных задач, есть готовые модели, есть надстройки над библиотекой transformers. Если, обучать BERT на GPU (можно в Google Colab или Kaggle), то должно быть побыстрее.\\\n",
    "https://huggingface.co/transformers/model_doc/bert.html \\\n",
    "https://t.me/renat_alimbekov \\\n",
    "https://colah.github.io/posts/2015-08-Understanding-LSTMs/ - Про LSTM \\\n",
    "https://web.stanford.edu/~jurafsky/slp3/10.pdf - про энкодер-декодер модели, этеншены\\\n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html - официальный гайд\n",
    "по трансформеру от создателей pytorch\\\n",
    "https://transformer.huggingface.co/ - поболтать с трансформером \\\n",
    "Библиотеки: allennlp, fairseq, transformers, tensorflow-text — множествореализованных\n",
    "методов для трансформеров методов NLP \\\n",
    "Word2Vec https://radimrehurek.com/gensim/models/word2vec.html \n",
    "\n",
    "<font color='green'>Пример BERT с GPU:\n",
    "```python\n",
    "%%time\n",
    "from tqdm import notebook\n",
    "batch_size = 2 # для примера возьмем такой батч, где будет всего две строки датасета\n",
    "embeddings = [] \n",
    "for i in notebook.tqdm(range(input_ids.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(input_ids[batch_size*i:batch_size*(i+1)]).cuda() # закидываем тензор на GPU\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.cuda()\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy()) # перевод обратно на проц, чтобы в нумпай кинуть\n",
    "        del batch\n",
    "        del attention_mask_batch\n",
    "        del batch_embeddings\n",
    "        \n",
    "features = np.concatenate(embeddings) \n",
    "```\n",
    "Можно сделать предварительную проверку на наличие GPU.\\\n",
    "Например, так: ```device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")```\\\n",
    "Тогда вместо .cuda() нужно писать .to(device)\n",
    "\n",
    "Если понравилась работа с текстами, то можешь посмотреть очень интересный (но очень-очень сложный) курс лекций: https://github.com/yandexdataschool/nlp_course .\n",
    "</font>\n",
    "\n",
    "### <font color='orange'>Общее впечатление</font>\n",
    "* Большое спасибо за проделанную работу. Видно, что приложено много усилий.\n",
    "* Радует, что ноутбук хорошо структурирован. Приятно проверять такие работы.\n",
    "* Работа получилась отличной, тебе удалось добиться достаточно хорошего качества. Поздравляю!\n",
    "* Проект может быть зачтен, но я его отправлю назад, чтобы у тебя была возможность задать вопросы и внести правки, при желании. Однако, ты можешь просто вернуть проект в таком же виде и я его зачту."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import notebook\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from catboost import Pool, CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Отлично, что все импорты собраны в первой ячейке ноутбука! Если у того, кто будет запускать твой ноутбук будут отсутствовать некоторые библиотеки, то он это увидит сразу, а не в процессе!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Общее-впечатление\" data-toc-modified-id=\"Общее-впечатление-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление</font></a></span></li></ul></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» c BERT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные, чтобы модно было работать и локально и удаленно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159446</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159447</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159448</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159449</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159450</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159446  \":::::And for the second time of asking, when ...      0\n",
       "159447  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159448  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159449  And it looks like it was actually you who put ...      0\n",
       "159450  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159292 rows x 2 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    data = pd.read_csv('../datasets/toxic_comments.csv', index_col=[0], parse_dates=[0])\n",
    "\n",
    "except:\n",
    "    data = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv', index_col=[0], parse_dates=[0])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Супер, пропущенных значений нет и признаки приведены к нужному типу, так что предобработка не нужна!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента V1</b>\n",
    "Когда уже отправил работу более подробно разобрался с ограничениями в BERT и по итогу не 512 слов, а 512 токенов, поэтому переделал чуть-чуть, не вырезая датасет. :)\n",
    "Вопросов нет, спасибо за ревью :)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data[data['text'].apply(lambda x: len(x) < 501)]\n",
    "# data = data.reset_index(drop=True)\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Данные загружены корреткно. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем 5000 объектов случаным образов для токенизации и обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента V1</b>\n",
    "По твоему совету взял больше объектов!\n",
    "UPD: Перед отправкой случайно перезапустил ядро и чтобы заново не обучалось около часа запустил на 400 :(\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Expert Categorizers  \\n\\nWhy is there no menti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"\\n\\n Noise \\n\\nfart*  talk. \"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An indefinite block is appropriate, even for a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I don't understand why we have a screenshot of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello! Some of the people, places or things yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Dear Patchy1, \\nI want briefly to thank again ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>(UTC)\\n\\nWouldn't it be ironic if, when Paul d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>Re your message \\n\\nThe votes were wrong, so I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>You are clearly 64.85.234.166 \\nOnce again. VO...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>\"\\nI will presume you meant nonsense, in that ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  toxic\n",
       "0    Expert Categorizers  \\n\\nWhy is there no menti...      0\n",
       "1                       \"\\n\\n Noise \\n\\nfart*  talk. \"      1\n",
       "2    An indefinite block is appropriate, even for a...      0\n",
       "3    I don't understand why we have a screenshot of...      0\n",
       "4    Hello! Some of the people, places or things yo...      0\n",
       "..                                                 ...    ...\n",
       "395  Dear Patchy1, \\nI want briefly to thank again ...      0\n",
       "396  (UTC)\\n\\nWouldn't it be ironic if, when Paul d...      0\n",
       "397  Re your message \\n\\nThe votes were wrong, so I...      0\n",
       "398  You are clearly 64.85.234.166 \\nOnce again. VO...      0\n",
       "399  \"\\nI will presume you meant nonsense, in that ...      0\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sample(n=5000, random_state=12345).reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся уже обученным токенизатором и применим к нему наши 5000 обьектов!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"unitary/toxic-bert\")\n",
    "\n",
    "\n",
    "tokenized = data['text'].apply(\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы создать маску внимания найдем максимальную длинну токенов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим метод padding , чтобы после токенизации длины исходных текстов в корпусе были равными. Создадим маску внимания для действительно важных токенов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_len = 139\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 512)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем саму модель класса BertModel. Передадим ей файл с предобученной моделью и конфигурацией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at unitary/toxic-bert were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "config = transformers.BertConfig.from_json_file(\n",
    "    '../materials/config.json')\n",
    "model = AutoModel.from_pretrained(\"unitary/toxic-bert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de76c6b3f684a7496ee03208273467c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "embeddings = []\n",
    "\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "    batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)])\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "    embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили вектор фичей!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.6971476 , -0.82382864, -0.00980995, ..., -0.61050177,\n",
       "         0.46135366,  0.5302732 ],\n",
       "       [-0.24773656, -0.15625034,  0.8224681 , ..., -0.09236028,\n",
       "         0.6245883 ,  0.46453005],\n",
       "       [-0.592878  , -0.9860475 ,  0.62051255, ..., -0.697492  ,\n",
       "         0.22761132,  0.06570403],\n",
       "       ...,\n",
       "       [-0.5862033 , -0.9415446 ,  0.7713225 , ..., -0.62911016,\n",
       "         0.4985153 ,  0.07938204],\n",
       "       [-0.5516032 , -0.8113322 ,  0.83707374, ..., -0.558484  ,\n",
       "         0.73307544,  0.27838194],\n",
       "       [-0.4900895 , -0.8686372 ,  0.6613381 , ..., -0.59195   ,\n",
       "         0.5643599 ,  0.19814768]], dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate(embeddings)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем данные в соотношении 4:1 и не забывает про stratify!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112    0\n",
       "165    0\n",
       "154    0\n",
       "187    0\n",
       "33     0\n",
       "      ..\n",
       "296    0\n",
       "271    0\n",
       "373    0\n",
       "116    0\n",
       "297    1\n",
       "Name: toxic, Length: 320, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, data['toxic'], test_size=0.2, random_state=12345, stratify=data['toxic'])\n",
    "target_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Молодец, что освоил векторизацию с помощью БЕРТа!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Лучше было бы взять бОльший семпл данных.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим списки для записи лучших метрик и параметров, при которых они были получены, для итоговой таблицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_metrics = []\n",
    "best_params = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим Логистическую Регрессию и протесируем ее на кросс-валидации!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9664335664335664"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model  = LogisticRegression()\n",
    "log_model.fit(features_train, target_train)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "grid_log = cross_val_score(log_model, X=features_train, y=target_train, cv=cv, scoring='f1')\n",
    "best_metrics.append(round(grid_log.mean(), 5))\n",
    "best_params.append('No Params')\n",
    "grid_log.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 score = 0.94 - неплохо!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
    "             estimator=RandomForestClassifier(random_state=12345), n_jobs=-1,\n",
    "             param_grid={'max_depth': range(5, 26, 5),\n",
    "                         'n_estimators': range(100, 260, 50)},\n",
    "             scoring='f1', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также обучим Случайны Лес и подберем гипперпараметры!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "CPU times: user 522 ms, sys: 299 ms, total: 820 ms\n",
      "Wall time: 5.44 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=RandomForestClassifier(random_state=12345), n_jobs=-1,\n",
       "             param_grid={'max_depth': range(5, 26, 5),\n",
       "                         'n_estimators': range(100, 260, 50)},\n",
       "             scoring='f1', verbose=True)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "forest = RandomForestClassifier(random_state=12345)\n",
    "params = {'n_estimators': range(100, 260, 50), 'max_depth': range(5, 26, 5)}\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "grid = GridSearchCV(forest, params, n_jobs=-1, verbose=True, cv=cv, scoring='f1')\n",
    "grid.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 score = 0.93 - Хуже, чем у Логистической."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'max_depth': 5, 'n_estimators': 100}\n",
      "Лучший счет: 0.9328671328671329\n"
     ]
    }
   ],
   "source": [
    "best_metrics.append(round(grid.best_score_, 5))\n",
    "best_params.append(str(grid.best_params_))\n",
    "print('Лучшие параметры:', grid.best_params_)\n",
    "print('Лучший счет:', grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "bestTest = 0.9850746269\n",
    "bestIteration = 45\n",
    "\n",
    "{'depth': 5, 'l2_leaf_reg': 1, 'learning_rate': 0.1}\n",
    "CPU times: user 4h 11min 22s, sys: 7min 8s, total: 4h 18min 30s\n",
    "Wall time: 44min 46s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну и куда же без бустинга! Обучим и его и подберем гипперпараметры!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# cat_model = CatBoostClassifier(eval_metric=\"F1\")\n",
    "# params = {'learning_rate': [0.03, 0.1],\n",
    "#         'depth': [5, 7, 10, 20],\n",
    "#         'l2_leaf_reg': [1, 3, 7, 9]}\n",
    "# grid_search_result = cat_model.grid_search(params, X=features_train, y=target_train, cv = StratifiedKFold(n_splits=5))\n",
    "# print(grid_search_result['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот и лучший результат от бустинга! F1 score = 0.98!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(grid_search_result[\"params\"][\"depth\"])\n",
    "# print(grid_search_result[\"params\"][\"learning_rate\"])\n",
    "# print(grid_search_result[\"params\"][\"l2_leaf_reg\"])\n",
    "best_metrics.append(round(0.9850746269, 5))\n",
    "# best_params.append(str(grid_search_result['params']))\n",
    "best_depth = 5\n",
    "best_learning_rate = 0.1\n",
    "best_l2 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9285714\ttotal: 31.1ms\tremaining: 31.1s\n",
      "1:\tlearn: 0.9285714\ttotal: 46ms\tremaining: 23s\n",
      "2:\tlearn: 0.9830508\ttotal: 63.4ms\tremaining: 21.1s\n",
      "3:\tlearn: 0.9830508\ttotal: 81.2ms\tremaining: 20.2s\n",
      "4:\tlearn: 0.9830508\ttotal: 104ms\tremaining: 20.6s\n",
      "5:\tlearn: 0.9830508\ttotal: 147ms\tremaining: 24.3s\n",
      "6:\tlearn: 1.0000000\ttotal: 173ms\tremaining: 24.5s\n",
      "7:\tlearn: 1.0000000\ttotal: 193ms\tremaining: 24s\n",
      "8:\tlearn: 1.0000000\ttotal: 225ms\tremaining: 24.8s\n",
      "9:\tlearn: 1.0000000\ttotal: 246ms\tremaining: 24.4s\n",
      "10:\tlearn: 1.0000000\ttotal: 279ms\tremaining: 25.1s\n",
      "11:\tlearn: 1.0000000\ttotal: 315ms\tremaining: 25.9s\n",
      "12:\tlearn: 1.0000000\ttotal: 353ms\tremaining: 26.8s\n",
      "13:\tlearn: 1.0000000\ttotal: 384ms\tremaining: 27.1s\n",
      "14:\tlearn: 1.0000000\ttotal: 412ms\tremaining: 27.1s\n",
      "15:\tlearn: 1.0000000\ttotal: 431ms\tremaining: 26.5s\n",
      "16:\tlearn: 1.0000000\ttotal: 451ms\tremaining: 26.1s\n",
      "17:\tlearn: 1.0000000\ttotal: 470ms\tremaining: 25.7s\n",
      "18:\tlearn: 1.0000000\ttotal: 489ms\tremaining: 25.2s\n",
      "19:\tlearn: 1.0000000\ttotal: 521ms\tremaining: 25.5s\n",
      "20:\tlearn: 1.0000000\ttotal: 540ms\tremaining: 25.2s\n",
      "21:\tlearn: 1.0000000\ttotal: 568ms\tremaining: 25.2s\n",
      "22:\tlearn: 1.0000000\ttotal: 587ms\tremaining: 24.9s\n",
      "23:\tlearn: 1.0000000\ttotal: 604ms\tremaining: 24.6s\n",
      "24:\tlearn: 1.0000000\ttotal: 622ms\tremaining: 24.3s\n",
      "25:\tlearn: 1.0000000\ttotal: 640ms\tremaining: 24s\n",
      "26:\tlearn: 1.0000000\ttotal: 657ms\tremaining: 23.7s\n",
      "27:\tlearn: 1.0000000\ttotal: 673ms\tremaining: 23.4s\n",
      "28:\tlearn: 1.0000000\ttotal: 691ms\tremaining: 23.1s\n",
      "29:\tlearn: 1.0000000\ttotal: 708ms\tremaining: 22.9s\n",
      "30:\tlearn: 1.0000000\ttotal: 723ms\tremaining: 22.6s\n",
      "31:\tlearn: 1.0000000\ttotal: 739ms\tremaining: 22.3s\n",
      "32:\tlearn: 1.0000000\ttotal: 755ms\tremaining: 22.1s\n",
      "33:\tlearn: 1.0000000\ttotal: 770ms\tremaining: 21.9s\n",
      "34:\tlearn: 1.0000000\ttotal: 781ms\tremaining: 21.5s\n",
      "35:\tlearn: 1.0000000\ttotal: 796ms\tremaining: 21.3s\n",
      "36:\tlearn: 1.0000000\ttotal: 808ms\tremaining: 21s\n",
      "37:\tlearn: 1.0000000\ttotal: 822ms\tremaining: 20.8s\n",
      "38:\tlearn: 1.0000000\ttotal: 835ms\tremaining: 20.6s\n",
      "39:\tlearn: 1.0000000\ttotal: 847ms\tremaining: 20.3s\n",
      "40:\tlearn: 1.0000000\ttotal: 860ms\tremaining: 20.1s\n",
      "41:\tlearn: 1.0000000\ttotal: 874ms\tremaining: 19.9s\n",
      "42:\tlearn: 1.0000000\ttotal: 886ms\tremaining: 19.7s\n",
      "43:\tlearn: 1.0000000\ttotal: 899ms\tremaining: 19.5s\n",
      "44:\tlearn: 1.0000000\ttotal: 912ms\tremaining: 19.4s\n",
      "45:\tlearn: 1.0000000\ttotal: 926ms\tremaining: 19.2s\n",
      "46:\tlearn: 1.0000000\ttotal: 939ms\tremaining: 19s\n",
      "47:\tlearn: 1.0000000\ttotal: 951ms\tremaining: 18.9s\n",
      "48:\tlearn: 1.0000000\ttotal: 964ms\tremaining: 18.7s\n",
      "49:\tlearn: 1.0000000\ttotal: 976ms\tremaining: 18.6s\n",
      "50:\tlearn: 1.0000000\ttotal: 989ms\tremaining: 18.4s\n",
      "51:\tlearn: 1.0000000\ttotal: 1s\tremaining: 18.2s\n",
      "52:\tlearn: 1.0000000\ttotal: 1.01s\tremaining: 18.1s\n",
      "53:\tlearn: 1.0000000\ttotal: 1.03s\tremaining: 18s\n",
      "54:\tlearn: 1.0000000\ttotal: 1.04s\tremaining: 17.9s\n",
      "55:\tlearn: 1.0000000\ttotal: 1.05s\tremaining: 17.7s\n",
      "56:\tlearn: 1.0000000\ttotal: 1.06s\tremaining: 17.6s\n",
      "57:\tlearn: 1.0000000\ttotal: 1.08s\tremaining: 17.5s\n",
      "58:\tlearn: 1.0000000\ttotal: 1.09s\tremaining: 17.4s\n",
      "59:\tlearn: 1.0000000\ttotal: 1.1s\tremaining: 17.3s\n",
      "60:\tlearn: 1.0000000\ttotal: 1.12s\tremaining: 17.2s\n",
      "61:\tlearn: 1.0000000\ttotal: 1.13s\tremaining: 17.1s\n",
      "62:\tlearn: 1.0000000\ttotal: 1.15s\tremaining: 17s\n",
      "63:\tlearn: 1.0000000\ttotal: 1.16s\tremaining: 16.9s\n",
      "64:\tlearn: 1.0000000\ttotal: 1.17s\tremaining: 16.8s\n",
      "65:\tlearn: 1.0000000\ttotal: 1.18s\tremaining: 16.7s\n",
      "66:\tlearn: 1.0000000\ttotal: 1.19s\tremaining: 16.6s\n",
      "67:\tlearn: 1.0000000\ttotal: 1.21s\tremaining: 16.6s\n",
      "68:\tlearn: 1.0000000\ttotal: 1.23s\tremaining: 16.6s\n",
      "69:\tlearn: 1.0000000\ttotal: 1.25s\tremaining: 16.7s\n",
      "70:\tlearn: 1.0000000\ttotal: 1.28s\tremaining: 16.7s\n",
      "71:\tlearn: 1.0000000\ttotal: 1.3s\tremaining: 16.8s\n",
      "72:\tlearn: 1.0000000\ttotal: 1.32s\tremaining: 16.8s\n",
      "73:\tlearn: 1.0000000\ttotal: 1.34s\tremaining: 16.7s\n",
      "74:\tlearn: 1.0000000\ttotal: 1.35s\tremaining: 16.6s\n",
      "75:\tlearn: 1.0000000\ttotal: 1.36s\tremaining: 16.6s\n",
      "76:\tlearn: 1.0000000\ttotal: 1.37s\tremaining: 16.5s\n",
      "77:\tlearn: 1.0000000\ttotal: 1.39s\tremaining: 16.4s\n",
      "78:\tlearn: 1.0000000\ttotal: 1.4s\tremaining: 16.3s\n",
      "79:\tlearn: 1.0000000\ttotal: 1.41s\tremaining: 16.2s\n",
      "80:\tlearn: 1.0000000\ttotal: 1.42s\tremaining: 16.2s\n",
      "81:\tlearn: 1.0000000\ttotal: 1.44s\tremaining: 16.1s\n",
      "82:\tlearn: 1.0000000\ttotal: 1.45s\tremaining: 16s\n",
      "83:\tlearn: 1.0000000\ttotal: 1.46s\tremaining: 16s\n",
      "84:\tlearn: 1.0000000\ttotal: 1.48s\tremaining: 15.9s\n",
      "85:\tlearn: 1.0000000\ttotal: 1.49s\tremaining: 15.8s\n",
      "86:\tlearn: 1.0000000\ttotal: 1.5s\tremaining: 15.7s\n",
      "87:\tlearn: 1.0000000\ttotal: 1.51s\tremaining: 15.7s\n",
      "88:\tlearn: 1.0000000\ttotal: 1.53s\tremaining: 15.6s\n",
      "89:\tlearn: 1.0000000\ttotal: 1.54s\tremaining: 15.6s\n",
      "90:\tlearn: 1.0000000\ttotal: 1.55s\tremaining: 15.5s\n",
      "91:\tlearn: 1.0000000\ttotal: 1.56s\tremaining: 15.4s\n",
      "92:\tlearn: 1.0000000\ttotal: 1.58s\tremaining: 15.4s\n",
      "93:\tlearn: 1.0000000\ttotal: 1.59s\tremaining: 15.3s\n",
      "94:\tlearn: 1.0000000\ttotal: 1.6s\tremaining: 15.3s\n",
      "95:\tlearn: 1.0000000\ttotal: 1.61s\tremaining: 15.2s\n",
      "96:\tlearn: 1.0000000\ttotal: 1.63s\tremaining: 15.1s\n",
      "97:\tlearn: 1.0000000\ttotal: 1.64s\tremaining: 15.1s\n",
      "98:\tlearn: 1.0000000\ttotal: 1.65s\tremaining: 15s\n",
      "99:\tlearn: 1.0000000\ttotal: 1.67s\tremaining: 15s\n",
      "100:\tlearn: 1.0000000\ttotal: 1.68s\tremaining: 15s\n",
      "101:\tlearn: 1.0000000\ttotal: 1.69s\tremaining: 14.9s\n",
      "102:\tlearn: 1.0000000\ttotal: 1.71s\tremaining: 14.8s\n",
      "103:\tlearn: 1.0000000\ttotal: 1.72s\tremaining: 14.8s\n",
      "104:\tlearn: 1.0000000\ttotal: 1.73s\tremaining: 14.8s\n",
      "105:\tlearn: 1.0000000\ttotal: 1.75s\tremaining: 14.8s\n",
      "106:\tlearn: 1.0000000\ttotal: 1.76s\tremaining: 14.7s\n",
      "107:\tlearn: 1.0000000\ttotal: 1.77s\tremaining: 14.7s\n",
      "108:\tlearn: 1.0000000\ttotal: 1.79s\tremaining: 14.6s\n",
      "109:\tlearn: 1.0000000\ttotal: 1.8s\tremaining: 14.6s\n",
      "110:\tlearn: 1.0000000\ttotal: 1.82s\tremaining: 14.6s\n",
      "111:\tlearn: 1.0000000\ttotal: 1.83s\tremaining: 14.5s\n",
      "112:\tlearn: 1.0000000\ttotal: 1.84s\tremaining: 14.5s\n",
      "113:\tlearn: 1.0000000\ttotal: 1.86s\tremaining: 14.4s\n",
      "114:\tlearn: 1.0000000\ttotal: 1.87s\tremaining: 14.4s\n",
      "115:\tlearn: 1.0000000\ttotal: 1.89s\tremaining: 14.4s\n",
      "116:\tlearn: 1.0000000\ttotal: 1.9s\tremaining: 14.3s\n",
      "117:\tlearn: 1.0000000\ttotal: 1.92s\tremaining: 14.3s\n",
      "118:\tlearn: 1.0000000\ttotal: 1.93s\tremaining: 14.3s\n",
      "119:\tlearn: 1.0000000\ttotal: 1.94s\tremaining: 14.2s\n",
      "120:\tlearn: 1.0000000\ttotal: 1.96s\tremaining: 14.2s\n",
      "121:\tlearn: 1.0000000\ttotal: 1.97s\tremaining: 14.2s\n",
      "122:\tlearn: 1.0000000\ttotal: 1.99s\tremaining: 14.2s\n",
      "123:\tlearn: 1.0000000\ttotal: 2s\tremaining: 14.1s\n",
      "124:\tlearn: 1.0000000\ttotal: 2.01s\tremaining: 14.1s\n",
      "125:\tlearn: 1.0000000\ttotal: 2.02s\tremaining: 14s\n",
      "126:\tlearn: 1.0000000\ttotal: 2.04s\tremaining: 14s\n",
      "127:\tlearn: 1.0000000\ttotal: 2.05s\tremaining: 14s\n",
      "128:\tlearn: 1.0000000\ttotal: 2.07s\tremaining: 14s\n",
      "129:\tlearn: 1.0000000\ttotal: 2.08s\tremaining: 13.9s\n",
      "130:\tlearn: 1.0000000\ttotal: 2.09s\tremaining: 13.9s\n",
      "131:\tlearn: 1.0000000\ttotal: 2.11s\tremaining: 13.9s\n",
      "132:\tlearn: 1.0000000\ttotal: 2.12s\tremaining: 13.8s\n",
      "133:\tlearn: 1.0000000\ttotal: 2.14s\tremaining: 13.8s\n",
      "134:\tlearn: 1.0000000\ttotal: 2.15s\tremaining: 13.8s\n",
      "135:\tlearn: 1.0000000\ttotal: 2.17s\tremaining: 13.8s\n",
      "136:\tlearn: 1.0000000\ttotal: 2.19s\tremaining: 13.8s\n",
      "137:\tlearn: 1.0000000\ttotal: 2.2s\tremaining: 13.7s\n",
      "138:\tlearn: 1.0000000\ttotal: 2.21s\tremaining: 13.7s\n",
      "139:\tlearn: 1.0000000\ttotal: 2.23s\tremaining: 13.7s\n",
      "140:\tlearn: 1.0000000\ttotal: 2.24s\tremaining: 13.7s\n",
      "141:\tlearn: 1.0000000\ttotal: 2.26s\tremaining: 13.7s\n",
      "142:\tlearn: 1.0000000\ttotal: 2.27s\tremaining: 13.6s\n",
      "143:\tlearn: 1.0000000\ttotal: 2.29s\tremaining: 13.6s\n",
      "144:\tlearn: 1.0000000\ttotal: 2.31s\tremaining: 13.6s\n",
      "145:\tlearn: 1.0000000\ttotal: 2.33s\tremaining: 13.6s\n",
      "146:\tlearn: 1.0000000\ttotal: 2.34s\tremaining: 13.6s\n",
      "147:\tlearn: 1.0000000\ttotal: 2.36s\tremaining: 13.6s\n",
      "148:\tlearn: 1.0000000\ttotal: 2.37s\tremaining: 13.5s\n",
      "149:\tlearn: 1.0000000\ttotal: 2.38s\tremaining: 13.5s\n",
      "150:\tlearn: 1.0000000\ttotal: 2.4s\tremaining: 13.5s\n",
      "151:\tlearn: 1.0000000\ttotal: 2.41s\tremaining: 13.5s\n",
      "152:\tlearn: 1.0000000\ttotal: 2.43s\tremaining: 13.4s\n",
      "153:\tlearn: 1.0000000\ttotal: 2.44s\tremaining: 13.4s\n",
      "154:\tlearn: 1.0000000\ttotal: 2.45s\tremaining: 13.4s\n",
      "155:\tlearn: 1.0000000\ttotal: 2.47s\tremaining: 13.3s\n",
      "156:\tlearn: 1.0000000\ttotal: 2.48s\tremaining: 13.3s\n",
      "157:\tlearn: 1.0000000\ttotal: 2.5s\tremaining: 13.3s\n",
      "158:\tlearn: 1.0000000\ttotal: 2.51s\tremaining: 13.3s\n",
      "159:\tlearn: 1.0000000\ttotal: 2.52s\tremaining: 13.2s\n",
      "160:\tlearn: 1.0000000\ttotal: 2.54s\tremaining: 13.2s\n",
      "161:\tlearn: 1.0000000\ttotal: 2.55s\tremaining: 13.2s\n",
      "162:\tlearn: 1.0000000\ttotal: 2.56s\tremaining: 13.2s\n",
      "163:\tlearn: 1.0000000\ttotal: 2.58s\tremaining: 13.1s\n",
      "164:\tlearn: 1.0000000\ttotal: 2.59s\tremaining: 13.1s\n",
      "165:\tlearn: 1.0000000\ttotal: 2.61s\tremaining: 13.1s\n",
      "166:\tlearn: 1.0000000\ttotal: 2.62s\tremaining: 13.1s\n",
      "167:\tlearn: 1.0000000\ttotal: 2.64s\tremaining: 13.1s\n",
      "168:\tlearn: 1.0000000\ttotal: 2.65s\tremaining: 13s\n",
      "169:\tlearn: 1.0000000\ttotal: 2.66s\tremaining: 13s\n",
      "170:\tlearn: 1.0000000\ttotal: 2.68s\tremaining: 13s\n",
      "171:\tlearn: 1.0000000\ttotal: 2.69s\tremaining: 13s\n",
      "172:\tlearn: 1.0000000\ttotal: 2.71s\tremaining: 12.9s\n",
      "173:\tlearn: 1.0000000\ttotal: 2.72s\tremaining: 12.9s\n",
      "174:\tlearn: 1.0000000\ttotal: 2.73s\tremaining: 12.9s\n",
      "175:\tlearn: 1.0000000\ttotal: 2.75s\tremaining: 12.9s\n",
      "176:\tlearn: 1.0000000\ttotal: 2.76s\tremaining: 12.8s\n",
      "177:\tlearn: 1.0000000\ttotal: 2.77s\tremaining: 12.8s\n",
      "178:\tlearn: 1.0000000\ttotal: 2.79s\tremaining: 12.8s\n",
      "179:\tlearn: 1.0000000\ttotal: 2.81s\tremaining: 12.8s\n",
      "180:\tlearn: 1.0000000\ttotal: 2.82s\tremaining: 12.8s\n",
      "181:\tlearn: 1.0000000\ttotal: 2.83s\tremaining: 12.7s\n",
      "182:\tlearn: 1.0000000\ttotal: 2.85s\tremaining: 12.7s\n",
      "183:\tlearn: 1.0000000\ttotal: 2.86s\tremaining: 12.7s\n",
      "184:\tlearn: 1.0000000\ttotal: 2.88s\tremaining: 12.7s\n",
      "185:\tlearn: 1.0000000\ttotal: 2.89s\tremaining: 12.6s\n",
      "186:\tlearn: 1.0000000\ttotal: 2.91s\tremaining: 12.6s\n",
      "187:\tlearn: 1.0000000\ttotal: 2.92s\tremaining: 12.6s\n",
      "188:\tlearn: 1.0000000\ttotal: 2.94s\tremaining: 12.6s\n",
      "189:\tlearn: 1.0000000\ttotal: 2.96s\tremaining: 12.6s\n",
      "190:\tlearn: 1.0000000\ttotal: 2.98s\tremaining: 12.6s\n",
      "191:\tlearn: 1.0000000\ttotal: 2.99s\tremaining: 12.6s\n",
      "192:\tlearn: 1.0000000\ttotal: 3.01s\tremaining: 12.6s\n",
      "193:\tlearn: 1.0000000\ttotal: 3.03s\tremaining: 12.6s\n",
      "194:\tlearn: 1.0000000\ttotal: 3.05s\tremaining: 12.6s\n",
      "195:\tlearn: 1.0000000\ttotal: 3.06s\tremaining: 12.6s\n",
      "196:\tlearn: 1.0000000\ttotal: 3.08s\tremaining: 12.5s\n",
      "197:\tlearn: 1.0000000\ttotal: 3.09s\tremaining: 12.5s\n",
      "198:\tlearn: 1.0000000\ttotal: 3.11s\tremaining: 12.5s\n",
      "199:\tlearn: 1.0000000\ttotal: 3.13s\tremaining: 12.5s\n",
      "200:\tlearn: 1.0000000\ttotal: 3.15s\tremaining: 12.5s\n",
      "201:\tlearn: 1.0000000\ttotal: 3.16s\tremaining: 12.5s\n",
      "202:\tlearn: 1.0000000\ttotal: 3.18s\tremaining: 12.5s\n",
      "203:\tlearn: 1.0000000\ttotal: 3.19s\tremaining: 12.5s\n",
      "204:\tlearn: 1.0000000\ttotal: 3.21s\tremaining: 12.5s\n",
      "205:\tlearn: 1.0000000\ttotal: 3.23s\tremaining: 12.4s\n",
      "206:\tlearn: 1.0000000\ttotal: 3.24s\tremaining: 12.4s\n",
      "207:\tlearn: 1.0000000\ttotal: 3.26s\tremaining: 12.4s\n",
      "208:\tlearn: 1.0000000\ttotal: 3.28s\tremaining: 12.4s\n",
      "209:\tlearn: 1.0000000\ttotal: 3.3s\tremaining: 12.4s\n",
      "210:\tlearn: 1.0000000\ttotal: 3.32s\tremaining: 12.4s\n",
      "211:\tlearn: 1.0000000\ttotal: 3.34s\tremaining: 12.4s\n",
      "212:\tlearn: 1.0000000\ttotal: 3.35s\tremaining: 12.4s\n",
      "213:\tlearn: 1.0000000\ttotal: 3.37s\tremaining: 12.4s\n",
      "214:\tlearn: 1.0000000\ttotal: 3.39s\tremaining: 12.4s\n",
      "215:\tlearn: 1.0000000\ttotal: 3.41s\tremaining: 12.4s\n",
      "216:\tlearn: 1.0000000\ttotal: 3.42s\tremaining: 12.4s\n",
      "217:\tlearn: 1.0000000\ttotal: 3.44s\tremaining: 12.3s\n",
      "218:\tlearn: 1.0000000\ttotal: 3.47s\tremaining: 12.4s\n",
      "219:\tlearn: 1.0000000\ttotal: 3.48s\tremaining: 12.4s\n",
      "220:\tlearn: 1.0000000\ttotal: 3.5s\tremaining: 12.3s\n",
      "221:\tlearn: 1.0000000\ttotal: 3.52s\tremaining: 12.3s\n",
      "222:\tlearn: 1.0000000\ttotal: 3.54s\tremaining: 12.3s\n",
      "223:\tlearn: 1.0000000\ttotal: 3.56s\tremaining: 12.3s\n",
      "224:\tlearn: 1.0000000\ttotal: 3.58s\tremaining: 12.3s\n",
      "225:\tlearn: 1.0000000\ttotal: 3.6s\tremaining: 12.3s\n",
      "226:\tlearn: 1.0000000\ttotal: 3.61s\tremaining: 12.3s\n",
      "227:\tlearn: 1.0000000\ttotal: 3.63s\tremaining: 12.3s\n",
      "228:\tlearn: 1.0000000\ttotal: 3.65s\tremaining: 12.3s\n",
      "229:\tlearn: 1.0000000\ttotal: 3.67s\tremaining: 12.3s\n",
      "230:\tlearn: 1.0000000\ttotal: 3.69s\tremaining: 12.3s\n",
      "231:\tlearn: 1.0000000\ttotal: 3.7s\tremaining: 12.3s\n",
      "232:\tlearn: 1.0000000\ttotal: 3.72s\tremaining: 12.2s\n",
      "233:\tlearn: 1.0000000\ttotal: 3.73s\tremaining: 12.2s\n",
      "234:\tlearn: 1.0000000\ttotal: 3.75s\tremaining: 12.2s\n",
      "235:\tlearn: 1.0000000\ttotal: 3.76s\tremaining: 12.2s\n",
      "236:\tlearn: 1.0000000\ttotal: 3.77s\tremaining: 12.2s\n",
      "237:\tlearn: 1.0000000\ttotal: 3.79s\tremaining: 12.1s\n",
      "238:\tlearn: 1.0000000\ttotal: 3.8s\tremaining: 12.1s\n",
      "239:\tlearn: 1.0000000\ttotal: 3.82s\tremaining: 12.1s\n",
      "240:\tlearn: 1.0000000\ttotal: 3.83s\tremaining: 12.1s\n",
      "241:\tlearn: 1.0000000\ttotal: 3.85s\tremaining: 12s\n",
      "242:\tlearn: 1.0000000\ttotal: 3.86s\tremaining: 12s\n",
      "243:\tlearn: 1.0000000\ttotal: 3.87s\tremaining: 12s\n",
      "244:\tlearn: 1.0000000\ttotal: 3.89s\tremaining: 12s\n",
      "245:\tlearn: 1.0000000\ttotal: 3.9s\tremaining: 12s\n",
      "246:\tlearn: 1.0000000\ttotal: 3.91s\tremaining: 11.9s\n",
      "247:\tlearn: 1.0000000\ttotal: 3.93s\tremaining: 11.9s\n",
      "248:\tlearn: 1.0000000\ttotal: 3.94s\tremaining: 11.9s\n",
      "249:\tlearn: 1.0000000\ttotal: 3.96s\tremaining: 11.9s\n",
      "250:\tlearn: 1.0000000\ttotal: 3.97s\tremaining: 11.8s\n",
      "251:\tlearn: 1.0000000\ttotal: 3.98s\tremaining: 11.8s\n",
      "252:\tlearn: 1.0000000\ttotal: 4s\tremaining: 11.8s\n",
      "253:\tlearn: 1.0000000\ttotal: 4.01s\tremaining: 11.8s\n",
      "254:\tlearn: 1.0000000\ttotal: 4.03s\tremaining: 11.8s\n",
      "255:\tlearn: 1.0000000\ttotal: 4.04s\tremaining: 11.8s\n",
      "256:\tlearn: 1.0000000\ttotal: 4.06s\tremaining: 11.7s\n",
      "257:\tlearn: 1.0000000\ttotal: 4.07s\tremaining: 11.7s\n",
      "258:\tlearn: 1.0000000\ttotal: 4.08s\tremaining: 11.7s\n",
      "259:\tlearn: 1.0000000\ttotal: 4.1s\tremaining: 11.7s\n",
      "260:\tlearn: 1.0000000\ttotal: 4.11s\tremaining: 11.6s\n",
      "261:\tlearn: 1.0000000\ttotal: 4.12s\tremaining: 11.6s\n",
      "262:\tlearn: 1.0000000\ttotal: 4.14s\tremaining: 11.6s\n",
      "263:\tlearn: 1.0000000\ttotal: 4.15s\tremaining: 11.6s\n",
      "264:\tlearn: 1.0000000\ttotal: 4.17s\tremaining: 11.6s\n",
      "265:\tlearn: 1.0000000\ttotal: 4.18s\tremaining: 11.5s\n",
      "266:\tlearn: 1.0000000\ttotal: 4.19s\tremaining: 11.5s\n",
      "267:\tlearn: 1.0000000\ttotal: 4.21s\tremaining: 11.5s\n",
      "268:\tlearn: 1.0000000\ttotal: 4.22s\tremaining: 11.5s\n",
      "269:\tlearn: 1.0000000\ttotal: 4.24s\tremaining: 11.5s\n",
      "270:\tlearn: 1.0000000\ttotal: 4.25s\tremaining: 11.4s\n",
      "271:\tlearn: 1.0000000\ttotal: 4.26s\tremaining: 11.4s\n",
      "272:\tlearn: 1.0000000\ttotal: 4.28s\tremaining: 11.4s\n",
      "273:\tlearn: 1.0000000\ttotal: 4.29s\tremaining: 11.4s\n",
      "274:\tlearn: 1.0000000\ttotal: 4.3s\tremaining: 11.3s\n",
      "275:\tlearn: 1.0000000\ttotal: 4.32s\tremaining: 11.3s\n",
      "276:\tlearn: 1.0000000\ttotal: 4.33s\tremaining: 11.3s\n",
      "277:\tlearn: 1.0000000\ttotal: 4.34s\tremaining: 11.3s\n",
      "278:\tlearn: 1.0000000\ttotal: 4.36s\tremaining: 11.3s\n",
      "279:\tlearn: 1.0000000\ttotal: 4.37s\tremaining: 11.2s\n",
      "280:\tlearn: 1.0000000\ttotal: 4.38s\tremaining: 11.2s\n",
      "281:\tlearn: 1.0000000\ttotal: 4.4s\tremaining: 11.2s\n",
      "282:\tlearn: 1.0000000\ttotal: 4.42s\tremaining: 11.2s\n",
      "283:\tlearn: 1.0000000\ttotal: 4.43s\tremaining: 11.2s\n",
      "284:\tlearn: 1.0000000\ttotal: 4.45s\tremaining: 11.2s\n",
      "285:\tlearn: 1.0000000\ttotal: 4.46s\tremaining: 11.1s\n",
      "286:\tlearn: 1.0000000\ttotal: 4.48s\tremaining: 11.1s\n",
      "287:\tlearn: 1.0000000\ttotal: 4.49s\tremaining: 11.1s\n",
      "288:\tlearn: 1.0000000\ttotal: 4.5s\tremaining: 11.1s\n",
      "289:\tlearn: 1.0000000\ttotal: 4.52s\tremaining: 11.1s\n",
      "290:\tlearn: 1.0000000\ttotal: 4.53s\tremaining: 11s\n",
      "291:\tlearn: 1.0000000\ttotal: 4.54s\tremaining: 11s\n",
      "292:\tlearn: 1.0000000\ttotal: 4.55s\tremaining: 11s\n",
      "293:\tlearn: 1.0000000\ttotal: 4.57s\tremaining: 11s\n",
      "294:\tlearn: 1.0000000\ttotal: 4.58s\tremaining: 11s\n",
      "295:\tlearn: 1.0000000\ttotal: 4.6s\tremaining: 10.9s\n",
      "296:\tlearn: 1.0000000\ttotal: 4.61s\tremaining: 10.9s\n",
      "297:\tlearn: 1.0000000\ttotal: 4.63s\tremaining: 10.9s\n",
      "298:\tlearn: 1.0000000\ttotal: 4.64s\tremaining: 10.9s\n",
      "299:\tlearn: 1.0000000\ttotal: 4.66s\tremaining: 10.9s\n",
      "300:\tlearn: 1.0000000\ttotal: 4.67s\tremaining: 10.8s\n",
      "301:\tlearn: 1.0000000\ttotal: 4.68s\tremaining: 10.8s\n",
      "302:\tlearn: 1.0000000\ttotal: 4.7s\tremaining: 10.8s\n",
      "303:\tlearn: 1.0000000\ttotal: 4.71s\tremaining: 10.8s\n",
      "304:\tlearn: 1.0000000\ttotal: 4.72s\tremaining: 10.8s\n",
      "305:\tlearn: 1.0000000\ttotal: 4.74s\tremaining: 10.7s\n",
      "306:\tlearn: 1.0000000\ttotal: 4.75s\tremaining: 10.7s\n",
      "307:\tlearn: 1.0000000\ttotal: 4.77s\tremaining: 10.7s\n",
      "308:\tlearn: 1.0000000\ttotal: 4.78s\tremaining: 10.7s\n",
      "309:\tlearn: 1.0000000\ttotal: 4.8s\tremaining: 10.7s\n",
      "310:\tlearn: 1.0000000\ttotal: 4.81s\tremaining: 10.7s\n",
      "311:\tlearn: 1.0000000\ttotal: 4.83s\tremaining: 10.6s\n",
      "312:\tlearn: 1.0000000\ttotal: 4.84s\tremaining: 10.6s\n",
      "313:\tlearn: 1.0000000\ttotal: 4.85s\tremaining: 10.6s\n",
      "314:\tlearn: 1.0000000\ttotal: 4.86s\tremaining: 10.6s\n",
      "315:\tlearn: 1.0000000\ttotal: 4.88s\tremaining: 10.6s\n",
      "316:\tlearn: 1.0000000\ttotal: 4.89s\tremaining: 10.5s\n",
      "317:\tlearn: 1.0000000\ttotal: 4.91s\tremaining: 10.5s\n",
      "318:\tlearn: 1.0000000\ttotal: 4.92s\tremaining: 10.5s\n",
      "319:\tlearn: 1.0000000\ttotal: 4.93s\tremaining: 10.5s\n",
      "320:\tlearn: 1.0000000\ttotal: 4.94s\tremaining: 10.5s\n",
      "321:\tlearn: 1.0000000\ttotal: 4.96s\tremaining: 10.4s\n",
      "322:\tlearn: 1.0000000\ttotal: 4.97s\tremaining: 10.4s\n",
      "323:\tlearn: 1.0000000\ttotal: 4.98s\tremaining: 10.4s\n",
      "324:\tlearn: 1.0000000\ttotal: 4.99s\tremaining: 10.4s\n",
      "325:\tlearn: 1.0000000\ttotal: 5.01s\tremaining: 10.4s\n",
      "326:\tlearn: 1.0000000\ttotal: 5.02s\tremaining: 10.3s\n",
      "327:\tlearn: 1.0000000\ttotal: 5.03s\tremaining: 10.3s\n",
      "328:\tlearn: 1.0000000\ttotal: 5.05s\tremaining: 10.3s\n",
      "329:\tlearn: 1.0000000\ttotal: 5.06s\tremaining: 10.3s\n",
      "330:\tlearn: 1.0000000\ttotal: 5.07s\tremaining: 10.3s\n",
      "331:\tlearn: 1.0000000\ttotal: 5.09s\tremaining: 10.2s\n",
      "332:\tlearn: 1.0000000\ttotal: 5.1s\tremaining: 10.2s\n",
      "333:\tlearn: 1.0000000\ttotal: 5.11s\tremaining: 10.2s\n",
      "334:\tlearn: 1.0000000\ttotal: 5.12s\tremaining: 10.2s\n",
      "335:\tlearn: 1.0000000\ttotal: 5.13s\tremaining: 10.1s\n",
      "336:\tlearn: 1.0000000\ttotal: 5.15s\tremaining: 10.1s\n",
      "337:\tlearn: 1.0000000\ttotal: 5.16s\tremaining: 10.1s\n",
      "338:\tlearn: 1.0000000\ttotal: 5.17s\tremaining: 10.1s\n",
      "339:\tlearn: 1.0000000\ttotal: 5.18s\tremaining: 10.1s\n",
      "340:\tlearn: 1.0000000\ttotal: 5.2s\tremaining: 10s\n",
      "341:\tlearn: 1.0000000\ttotal: 5.21s\tremaining: 10s\n",
      "342:\tlearn: 1.0000000\ttotal: 5.22s\tremaining: 10s\n",
      "343:\tlearn: 1.0000000\ttotal: 5.24s\tremaining: 9.99s\n",
      "344:\tlearn: 1.0000000\ttotal: 5.25s\tremaining: 9.97s\n",
      "345:\tlearn: 1.0000000\ttotal: 5.26s\tremaining: 9.95s\n",
      "346:\tlearn: 1.0000000\ttotal: 5.28s\tremaining: 9.93s\n",
      "347:\tlearn: 1.0000000\ttotal: 5.29s\tremaining: 9.91s\n",
      "348:\tlearn: 1.0000000\ttotal: 5.3s\tremaining: 9.89s\n",
      "349:\tlearn: 1.0000000\ttotal: 5.32s\tremaining: 9.87s\n",
      "350:\tlearn: 1.0000000\ttotal: 5.33s\tremaining: 9.85s\n",
      "351:\tlearn: 1.0000000\ttotal: 5.34s\tremaining: 9.83s\n",
      "352:\tlearn: 1.0000000\ttotal: 5.36s\tremaining: 9.82s\n",
      "353:\tlearn: 1.0000000\ttotal: 5.37s\tremaining: 9.8s\n",
      "354:\tlearn: 1.0000000\ttotal: 5.38s\tremaining: 9.78s\n",
      "355:\tlearn: 1.0000000\ttotal: 5.39s\tremaining: 9.76s\n",
      "356:\tlearn: 1.0000000\ttotal: 5.41s\tremaining: 9.74s\n",
      "357:\tlearn: 1.0000000\ttotal: 5.42s\tremaining: 9.72s\n",
      "358:\tlearn: 1.0000000\ttotal: 5.43s\tremaining: 9.7s\n",
      "359:\tlearn: 1.0000000\ttotal: 5.45s\tremaining: 9.68s\n",
      "360:\tlearn: 1.0000000\ttotal: 5.46s\tremaining: 9.66s\n",
      "361:\tlearn: 1.0000000\ttotal: 5.47s\tremaining: 9.64s\n",
      "362:\tlearn: 1.0000000\ttotal: 5.49s\tremaining: 9.63s\n",
      "363:\tlearn: 1.0000000\ttotal: 5.5s\tremaining: 9.61s\n",
      "364:\tlearn: 1.0000000\ttotal: 5.51s\tremaining: 9.59s\n",
      "365:\tlearn: 1.0000000\ttotal: 5.52s\tremaining: 9.56s\n",
      "366:\tlearn: 1.0000000\ttotal: 5.53s\tremaining: 9.54s\n",
      "367:\tlearn: 1.0000000\ttotal: 5.55s\tremaining: 9.53s\n",
      "368:\tlearn: 1.0000000\ttotal: 5.56s\tremaining: 9.51s\n",
      "369:\tlearn: 1.0000000\ttotal: 5.57s\tremaining: 9.49s\n",
      "370:\tlearn: 1.0000000\ttotal: 5.59s\tremaining: 9.47s\n",
      "371:\tlearn: 1.0000000\ttotal: 5.6s\tremaining: 9.45s\n",
      "372:\tlearn: 1.0000000\ttotal: 5.61s\tremaining: 9.43s\n",
      "373:\tlearn: 1.0000000\ttotal: 5.63s\tremaining: 9.42s\n",
      "374:\tlearn: 1.0000000\ttotal: 5.64s\tremaining: 9.4s\n",
      "375:\tlearn: 1.0000000\ttotal: 5.65s\tremaining: 9.38s\n",
      "376:\tlearn: 1.0000000\ttotal: 5.66s\tremaining: 9.36s\n",
      "377:\tlearn: 1.0000000\ttotal: 5.68s\tremaining: 9.34s\n",
      "378:\tlearn: 1.0000000\ttotal: 5.69s\tremaining: 9.32s\n",
      "379:\tlearn: 1.0000000\ttotal: 5.7s\tremaining: 9.3s\n",
      "380:\tlearn: 1.0000000\ttotal: 5.72s\tremaining: 9.29s\n",
      "381:\tlearn: 1.0000000\ttotal: 5.73s\tremaining: 9.27s\n",
      "382:\tlearn: 1.0000000\ttotal: 5.74s\tremaining: 9.25s\n",
      "383:\tlearn: 1.0000000\ttotal: 5.76s\tremaining: 9.24s\n",
      "384:\tlearn: 1.0000000\ttotal: 5.77s\tremaining: 9.22s\n",
      "385:\tlearn: 1.0000000\ttotal: 5.78s\tremaining: 9.2s\n",
      "386:\tlearn: 1.0000000\ttotal: 5.8s\tremaining: 9.18s\n",
      "387:\tlearn: 1.0000000\ttotal: 5.81s\tremaining: 9.16s\n",
      "388:\tlearn: 1.0000000\ttotal: 5.83s\tremaining: 9.15s\n",
      "389:\tlearn: 1.0000000\ttotal: 5.84s\tremaining: 9.13s\n",
      "390:\tlearn: 1.0000000\ttotal: 5.85s\tremaining: 9.12s\n",
      "391:\tlearn: 1.0000000\ttotal: 5.87s\tremaining: 9.1s\n",
      "392:\tlearn: 1.0000000\ttotal: 5.88s\tremaining: 9.09s\n",
      "393:\tlearn: 1.0000000\ttotal: 5.89s\tremaining: 9.07s\n",
      "394:\tlearn: 1.0000000\ttotal: 5.91s\tremaining: 9.05s\n",
      "395:\tlearn: 1.0000000\ttotal: 5.93s\tremaining: 9.04s\n",
      "396:\tlearn: 1.0000000\ttotal: 5.94s\tremaining: 9.02s\n",
      "397:\tlearn: 1.0000000\ttotal: 5.96s\tremaining: 9.01s\n",
      "398:\tlearn: 1.0000000\ttotal: 5.97s\tremaining: 9s\n",
      "399:\tlearn: 1.0000000\ttotal: 5.99s\tremaining: 8.98s\n",
      "400:\tlearn: 1.0000000\ttotal: 6s\tremaining: 8.97s\n",
      "401:\tlearn: 1.0000000\ttotal: 6.02s\tremaining: 8.95s\n",
      "402:\tlearn: 1.0000000\ttotal: 6.03s\tremaining: 8.94s\n",
      "403:\tlearn: 1.0000000\ttotal: 6.05s\tremaining: 8.93s\n",
      "404:\tlearn: 1.0000000\ttotal: 6.07s\tremaining: 8.91s\n",
      "405:\tlearn: 1.0000000\ttotal: 6.08s\tremaining: 8.89s\n",
      "406:\tlearn: 1.0000000\ttotal: 6.09s\tremaining: 8.88s\n",
      "407:\tlearn: 1.0000000\ttotal: 6.11s\tremaining: 8.87s\n",
      "408:\tlearn: 1.0000000\ttotal: 6.13s\tremaining: 8.85s\n",
      "409:\tlearn: 1.0000000\ttotal: 6.14s\tremaining: 8.84s\n",
      "410:\tlearn: 1.0000000\ttotal: 6.16s\tremaining: 8.82s\n",
      "411:\tlearn: 1.0000000\ttotal: 6.17s\tremaining: 8.81s\n",
      "412:\tlearn: 1.0000000\ttotal: 6.18s\tremaining: 8.79s\n",
      "413:\tlearn: 1.0000000\ttotal: 6.2s\tremaining: 8.78s\n",
      "414:\tlearn: 1.0000000\ttotal: 6.22s\tremaining: 8.76s\n",
      "415:\tlearn: 1.0000000\ttotal: 6.23s\tremaining: 8.75s\n",
      "416:\tlearn: 1.0000000\ttotal: 6.25s\tremaining: 8.73s\n",
      "417:\tlearn: 1.0000000\ttotal: 6.26s\tremaining: 8.72s\n",
      "418:\tlearn: 1.0000000\ttotal: 6.28s\tremaining: 8.71s\n",
      "419:\tlearn: 1.0000000\ttotal: 6.3s\tremaining: 8.7s\n",
      "420:\tlearn: 1.0000000\ttotal: 6.31s\tremaining: 8.68s\n",
      "421:\tlearn: 1.0000000\ttotal: 6.33s\tremaining: 8.67s\n",
      "422:\tlearn: 1.0000000\ttotal: 6.34s\tremaining: 8.65s\n",
      "423:\tlearn: 1.0000000\ttotal: 6.36s\tremaining: 8.64s\n",
      "424:\tlearn: 1.0000000\ttotal: 6.38s\tremaining: 8.63s\n",
      "425:\tlearn: 1.0000000\ttotal: 6.39s\tremaining: 8.61s\n",
      "426:\tlearn: 1.0000000\ttotal: 6.4s\tremaining: 8.59s\n",
      "427:\tlearn: 1.0000000\ttotal: 6.43s\tremaining: 8.59s\n",
      "428:\tlearn: 1.0000000\ttotal: 6.44s\tremaining: 8.57s\n",
      "429:\tlearn: 1.0000000\ttotal: 6.46s\tremaining: 8.56s\n",
      "430:\tlearn: 1.0000000\ttotal: 6.47s\tremaining: 8.55s\n",
      "431:\tlearn: 1.0000000\ttotal: 6.49s\tremaining: 8.53s\n",
      "432:\tlearn: 1.0000000\ttotal: 6.5s\tremaining: 8.52s\n",
      "433:\tlearn: 1.0000000\ttotal: 6.52s\tremaining: 8.51s\n",
      "434:\tlearn: 1.0000000\ttotal: 6.54s\tremaining: 8.49s\n",
      "435:\tlearn: 1.0000000\ttotal: 6.55s\tremaining: 8.47s\n",
      "436:\tlearn: 1.0000000\ttotal: 6.57s\tremaining: 8.46s\n",
      "437:\tlearn: 1.0000000\ttotal: 6.58s\tremaining: 8.44s\n",
      "438:\tlearn: 1.0000000\ttotal: 6.6s\tremaining: 8.43s\n",
      "439:\tlearn: 1.0000000\ttotal: 6.61s\tremaining: 8.41s\n",
      "440:\tlearn: 1.0000000\ttotal: 6.63s\tremaining: 8.4s\n",
      "441:\tlearn: 1.0000000\ttotal: 6.64s\tremaining: 8.38s\n",
      "442:\tlearn: 1.0000000\ttotal: 6.66s\tremaining: 8.37s\n",
      "443:\tlearn: 1.0000000\ttotal: 6.67s\tremaining: 8.36s\n",
      "444:\tlearn: 1.0000000\ttotal: 6.69s\tremaining: 8.34s\n",
      "445:\tlearn: 1.0000000\ttotal: 6.7s\tremaining: 8.32s\n",
      "446:\tlearn: 1.0000000\ttotal: 6.72s\tremaining: 8.31s\n",
      "447:\tlearn: 1.0000000\ttotal: 6.73s\tremaining: 8.29s\n",
      "448:\tlearn: 1.0000000\ttotal: 6.74s\tremaining: 8.28s\n",
      "449:\tlearn: 1.0000000\ttotal: 6.76s\tremaining: 8.26s\n",
      "450:\tlearn: 1.0000000\ttotal: 6.77s\tremaining: 8.24s\n",
      "451:\tlearn: 1.0000000\ttotal: 6.78s\tremaining: 8.22s\n",
      "452:\tlearn: 1.0000000\ttotal: 6.8s\tremaining: 8.21s\n",
      "453:\tlearn: 1.0000000\ttotal: 6.81s\tremaining: 8.19s\n",
      "454:\tlearn: 1.0000000\ttotal: 6.82s\tremaining: 8.17s\n",
      "455:\tlearn: 1.0000000\ttotal: 6.83s\tremaining: 8.15s\n",
      "456:\tlearn: 1.0000000\ttotal: 6.85s\tremaining: 8.14s\n",
      "457:\tlearn: 1.0000000\ttotal: 6.86s\tremaining: 8.12s\n",
      "458:\tlearn: 1.0000000\ttotal: 6.88s\tremaining: 8.1s\n",
      "459:\tlearn: 1.0000000\ttotal: 6.89s\tremaining: 8.09s\n",
      "460:\tlearn: 1.0000000\ttotal: 6.9s\tremaining: 8.07s\n",
      "461:\tlearn: 1.0000000\ttotal: 6.92s\tremaining: 8.05s\n",
      "462:\tlearn: 1.0000000\ttotal: 6.93s\tremaining: 8.04s\n",
      "463:\tlearn: 1.0000000\ttotal: 6.94s\tremaining: 8.02s\n",
      "464:\tlearn: 1.0000000\ttotal: 6.96s\tremaining: 8s\n",
      "465:\tlearn: 1.0000000\ttotal: 6.97s\tremaining: 7.99s\n",
      "466:\tlearn: 1.0000000\ttotal: 6.98s\tremaining: 7.97s\n",
      "467:\tlearn: 1.0000000\ttotal: 6.99s\tremaining: 7.95s\n",
      "468:\tlearn: 1.0000000\ttotal: 7.01s\tremaining: 7.93s\n",
      "469:\tlearn: 1.0000000\ttotal: 7.02s\tremaining: 7.92s\n",
      "470:\tlearn: 1.0000000\ttotal: 7.03s\tremaining: 7.9s\n",
      "471:\tlearn: 1.0000000\ttotal: 7.05s\tremaining: 7.88s\n",
      "472:\tlearn: 1.0000000\ttotal: 7.06s\tremaining: 7.87s\n",
      "473:\tlearn: 1.0000000\ttotal: 7.07s\tremaining: 7.85s\n",
      "474:\tlearn: 1.0000000\ttotal: 7.09s\tremaining: 7.83s\n",
      "475:\tlearn: 1.0000000\ttotal: 7.1s\tremaining: 7.82s\n",
      "476:\tlearn: 1.0000000\ttotal: 7.11s\tremaining: 7.8s\n",
      "477:\tlearn: 1.0000000\ttotal: 7.13s\tremaining: 7.78s\n",
      "478:\tlearn: 1.0000000\ttotal: 7.14s\tremaining: 7.77s\n",
      "479:\tlearn: 1.0000000\ttotal: 7.15s\tremaining: 7.75s\n",
      "480:\tlearn: 1.0000000\ttotal: 7.17s\tremaining: 7.73s\n",
      "481:\tlearn: 1.0000000\ttotal: 7.18s\tremaining: 7.72s\n",
      "482:\tlearn: 1.0000000\ttotal: 7.19s\tremaining: 7.7s\n",
      "483:\tlearn: 1.0000000\ttotal: 7.2s\tremaining: 7.68s\n",
      "484:\tlearn: 1.0000000\ttotal: 7.22s\tremaining: 7.66s\n",
      "485:\tlearn: 1.0000000\ttotal: 7.23s\tremaining: 7.65s\n",
      "486:\tlearn: 1.0000000\ttotal: 7.24s\tremaining: 7.63s\n",
      "487:\tlearn: 1.0000000\ttotal: 7.25s\tremaining: 7.61s\n",
      "488:\tlearn: 1.0000000\ttotal: 7.27s\tremaining: 7.59s\n",
      "489:\tlearn: 1.0000000\ttotal: 7.28s\tremaining: 7.58s\n",
      "490:\tlearn: 1.0000000\ttotal: 7.29s\tremaining: 7.56s\n",
      "491:\tlearn: 1.0000000\ttotal: 7.31s\tremaining: 7.54s\n",
      "492:\tlearn: 1.0000000\ttotal: 7.32s\tremaining: 7.53s\n",
      "493:\tlearn: 1.0000000\ttotal: 7.33s\tremaining: 7.51s\n",
      "494:\tlearn: 1.0000000\ttotal: 7.35s\tremaining: 7.5s\n",
      "495:\tlearn: 1.0000000\ttotal: 7.36s\tremaining: 7.48s\n",
      "496:\tlearn: 1.0000000\ttotal: 7.38s\tremaining: 7.46s\n",
      "497:\tlearn: 1.0000000\ttotal: 7.39s\tremaining: 7.45s\n",
      "498:\tlearn: 1.0000000\ttotal: 7.4s\tremaining: 7.43s\n",
      "499:\tlearn: 1.0000000\ttotal: 7.42s\tremaining: 7.42s\n",
      "500:\tlearn: 1.0000000\ttotal: 7.43s\tremaining: 7.4s\n",
      "501:\tlearn: 1.0000000\ttotal: 7.44s\tremaining: 7.38s\n",
      "502:\tlearn: 1.0000000\ttotal: 7.46s\tremaining: 7.37s\n",
      "503:\tlearn: 1.0000000\ttotal: 7.47s\tremaining: 7.35s\n",
      "504:\tlearn: 1.0000000\ttotal: 7.48s\tremaining: 7.33s\n",
      "505:\tlearn: 1.0000000\ttotal: 7.49s\tremaining: 7.32s\n",
      "506:\tlearn: 1.0000000\ttotal: 7.51s\tremaining: 7.3s\n",
      "507:\tlearn: 1.0000000\ttotal: 7.52s\tremaining: 7.28s\n",
      "508:\tlearn: 1.0000000\ttotal: 7.53s\tremaining: 7.27s\n",
      "509:\tlearn: 1.0000000\ttotal: 7.55s\tremaining: 7.25s\n",
      "510:\tlearn: 1.0000000\ttotal: 7.56s\tremaining: 7.24s\n",
      "511:\tlearn: 1.0000000\ttotal: 7.58s\tremaining: 7.22s\n",
      "512:\tlearn: 1.0000000\ttotal: 7.59s\tremaining: 7.21s\n",
      "513:\tlearn: 1.0000000\ttotal: 7.61s\tremaining: 7.19s\n",
      "514:\tlearn: 1.0000000\ttotal: 7.62s\tremaining: 7.18s\n",
      "515:\tlearn: 1.0000000\ttotal: 7.63s\tremaining: 7.16s\n",
      "516:\tlearn: 1.0000000\ttotal: 7.65s\tremaining: 7.14s\n",
      "517:\tlearn: 1.0000000\ttotal: 7.66s\tremaining: 7.13s\n",
      "518:\tlearn: 1.0000000\ttotal: 7.67s\tremaining: 7.11s\n",
      "519:\tlearn: 1.0000000\ttotal: 7.69s\tremaining: 7.09s\n",
      "520:\tlearn: 1.0000000\ttotal: 7.7s\tremaining: 7.08s\n",
      "521:\tlearn: 1.0000000\ttotal: 7.71s\tremaining: 7.06s\n",
      "522:\tlearn: 1.0000000\ttotal: 7.72s\tremaining: 7.04s\n",
      "523:\tlearn: 1.0000000\ttotal: 7.74s\tremaining: 7.03s\n",
      "524:\tlearn: 1.0000000\ttotal: 7.75s\tremaining: 7.01s\n",
      "525:\tlearn: 1.0000000\ttotal: 7.76s\tremaining: 7s\n",
      "526:\tlearn: 1.0000000\ttotal: 7.78s\tremaining: 6.98s\n",
      "527:\tlearn: 1.0000000\ttotal: 7.79s\tremaining: 6.96s\n",
      "528:\tlearn: 1.0000000\ttotal: 7.8s\tremaining: 6.95s\n",
      "529:\tlearn: 1.0000000\ttotal: 7.82s\tremaining: 6.93s\n",
      "530:\tlearn: 1.0000000\ttotal: 7.83s\tremaining: 6.91s\n",
      "531:\tlearn: 1.0000000\ttotal: 7.84s\tremaining: 6.9s\n",
      "532:\tlearn: 1.0000000\ttotal: 7.85s\tremaining: 6.88s\n",
      "533:\tlearn: 1.0000000\ttotal: 7.87s\tremaining: 6.86s\n",
      "534:\tlearn: 1.0000000\ttotal: 7.88s\tremaining: 6.85s\n",
      "535:\tlearn: 1.0000000\ttotal: 7.89s\tremaining: 6.83s\n",
      "536:\tlearn: 1.0000000\ttotal: 7.9s\tremaining: 6.81s\n",
      "537:\tlearn: 1.0000000\ttotal: 7.92s\tremaining: 6.8s\n",
      "538:\tlearn: 1.0000000\ttotal: 7.93s\tremaining: 6.78s\n",
      "539:\tlearn: 1.0000000\ttotal: 7.94s\tremaining: 6.77s\n",
      "540:\tlearn: 1.0000000\ttotal: 7.96s\tremaining: 6.75s\n",
      "541:\tlearn: 1.0000000\ttotal: 7.97s\tremaining: 6.73s\n",
      "542:\tlearn: 1.0000000\ttotal: 7.98s\tremaining: 6.72s\n",
      "543:\tlearn: 1.0000000\ttotal: 7.99s\tremaining: 6.7s\n",
      "544:\tlearn: 1.0000000\ttotal: 8.01s\tremaining: 6.68s\n",
      "545:\tlearn: 1.0000000\ttotal: 8.02s\tremaining: 6.67s\n",
      "546:\tlearn: 1.0000000\ttotal: 8.03s\tremaining: 6.65s\n",
      "547:\tlearn: 1.0000000\ttotal: 8.05s\tremaining: 6.64s\n",
      "548:\tlearn: 1.0000000\ttotal: 8.06s\tremaining: 6.62s\n",
      "549:\tlearn: 1.0000000\ttotal: 8.07s\tremaining: 6.61s\n",
      "550:\tlearn: 1.0000000\ttotal: 8.09s\tremaining: 6.59s\n",
      "551:\tlearn: 1.0000000\ttotal: 8.1s\tremaining: 6.58s\n",
      "552:\tlearn: 1.0000000\ttotal: 8.12s\tremaining: 6.56s\n",
      "553:\tlearn: 1.0000000\ttotal: 8.13s\tremaining: 6.54s\n",
      "554:\tlearn: 1.0000000\ttotal: 8.14s\tremaining: 6.53s\n",
      "555:\tlearn: 1.0000000\ttotal: 8.15s\tremaining: 6.51s\n",
      "556:\tlearn: 1.0000000\ttotal: 8.17s\tremaining: 6.5s\n",
      "557:\tlearn: 1.0000000\ttotal: 8.18s\tremaining: 6.48s\n",
      "558:\tlearn: 1.0000000\ttotal: 8.19s\tremaining: 6.46s\n",
      "559:\tlearn: 1.0000000\ttotal: 8.21s\tremaining: 6.45s\n",
      "560:\tlearn: 1.0000000\ttotal: 8.22s\tremaining: 6.43s\n",
      "561:\tlearn: 1.0000000\ttotal: 8.24s\tremaining: 6.42s\n",
      "562:\tlearn: 1.0000000\ttotal: 8.25s\tremaining: 6.41s\n",
      "563:\tlearn: 1.0000000\ttotal: 8.27s\tremaining: 6.39s\n",
      "564:\tlearn: 1.0000000\ttotal: 8.28s\tremaining: 6.37s\n",
      "565:\tlearn: 1.0000000\ttotal: 8.29s\tremaining: 6.36s\n",
      "566:\tlearn: 1.0000000\ttotal: 8.3s\tremaining: 6.34s\n",
      "567:\tlearn: 1.0000000\ttotal: 8.32s\tremaining: 6.33s\n",
      "568:\tlearn: 1.0000000\ttotal: 8.33s\tremaining: 6.31s\n",
      "569:\tlearn: 1.0000000\ttotal: 8.34s\tremaining: 6.29s\n",
      "570:\tlearn: 1.0000000\ttotal: 8.36s\tremaining: 6.28s\n",
      "571:\tlearn: 1.0000000\ttotal: 8.37s\tremaining: 6.26s\n",
      "572:\tlearn: 1.0000000\ttotal: 8.38s\tremaining: 6.25s\n",
      "573:\tlearn: 1.0000000\ttotal: 8.4s\tremaining: 6.23s\n",
      "574:\tlearn: 1.0000000\ttotal: 8.41s\tremaining: 6.22s\n",
      "575:\tlearn: 1.0000000\ttotal: 8.42s\tremaining: 6.2s\n",
      "576:\tlearn: 1.0000000\ttotal: 8.44s\tremaining: 6.18s\n",
      "577:\tlearn: 1.0000000\ttotal: 8.45s\tremaining: 6.17s\n",
      "578:\tlearn: 1.0000000\ttotal: 8.46s\tremaining: 6.15s\n",
      "579:\tlearn: 1.0000000\ttotal: 8.47s\tremaining: 6.13s\n",
      "580:\tlearn: 1.0000000\ttotal: 8.48s\tremaining: 6.12s\n",
      "581:\tlearn: 1.0000000\ttotal: 8.5s\tremaining: 6.1s\n",
      "582:\tlearn: 1.0000000\ttotal: 8.51s\tremaining: 6.09s\n",
      "583:\tlearn: 1.0000000\ttotal: 8.52s\tremaining: 6.07s\n",
      "584:\tlearn: 1.0000000\ttotal: 8.54s\tremaining: 6.06s\n",
      "585:\tlearn: 1.0000000\ttotal: 8.55s\tremaining: 6.04s\n",
      "586:\tlearn: 1.0000000\ttotal: 8.56s\tremaining: 6.02s\n",
      "587:\tlearn: 1.0000000\ttotal: 8.57s\tremaining: 6.01s\n",
      "588:\tlearn: 1.0000000\ttotal: 8.59s\tremaining: 5.99s\n",
      "589:\tlearn: 1.0000000\ttotal: 8.6s\tremaining: 5.98s\n",
      "590:\tlearn: 1.0000000\ttotal: 8.61s\tremaining: 5.96s\n",
      "591:\tlearn: 1.0000000\ttotal: 8.63s\tremaining: 5.95s\n",
      "592:\tlearn: 1.0000000\ttotal: 8.64s\tremaining: 5.93s\n",
      "593:\tlearn: 1.0000000\ttotal: 8.65s\tremaining: 5.91s\n",
      "594:\tlearn: 1.0000000\ttotal: 8.66s\tremaining: 5.9s\n",
      "595:\tlearn: 1.0000000\ttotal: 8.68s\tremaining: 5.88s\n",
      "596:\tlearn: 1.0000000\ttotal: 8.69s\tremaining: 5.87s\n",
      "597:\tlearn: 1.0000000\ttotal: 8.7s\tremaining: 5.85s\n",
      "598:\tlearn: 1.0000000\ttotal: 8.71s\tremaining: 5.83s\n",
      "599:\tlearn: 1.0000000\ttotal: 8.73s\tremaining: 5.82s\n",
      "600:\tlearn: 1.0000000\ttotal: 8.75s\tremaining: 5.81s\n",
      "601:\tlearn: 1.0000000\ttotal: 8.77s\tremaining: 5.79s\n",
      "602:\tlearn: 1.0000000\ttotal: 8.78s\tremaining: 5.78s\n",
      "603:\tlearn: 1.0000000\ttotal: 8.8s\tremaining: 5.77s\n",
      "604:\tlearn: 1.0000000\ttotal: 8.81s\tremaining: 5.75s\n",
      "605:\tlearn: 1.0000000\ttotal: 8.82s\tremaining: 5.74s\n",
      "606:\tlearn: 1.0000000\ttotal: 8.84s\tremaining: 5.72s\n",
      "607:\tlearn: 1.0000000\ttotal: 8.86s\tremaining: 5.71s\n",
      "608:\tlearn: 1.0000000\ttotal: 8.87s\tremaining: 5.7s\n",
      "609:\tlearn: 1.0000000\ttotal: 8.89s\tremaining: 5.68s\n",
      "610:\tlearn: 1.0000000\ttotal: 8.91s\tremaining: 5.67s\n",
      "611:\tlearn: 1.0000000\ttotal: 8.92s\tremaining: 5.66s\n",
      "612:\tlearn: 1.0000000\ttotal: 8.94s\tremaining: 5.64s\n",
      "613:\tlearn: 1.0000000\ttotal: 8.96s\tremaining: 5.63s\n",
      "614:\tlearn: 1.0000000\ttotal: 8.97s\tremaining: 5.62s\n",
      "615:\tlearn: 1.0000000\ttotal: 8.99s\tremaining: 5.61s\n",
      "616:\tlearn: 1.0000000\ttotal: 9.01s\tremaining: 5.59s\n",
      "617:\tlearn: 1.0000000\ttotal: 9.03s\tremaining: 5.58s\n",
      "618:\tlearn: 1.0000000\ttotal: 9.04s\tremaining: 5.57s\n",
      "619:\tlearn: 1.0000000\ttotal: 9.06s\tremaining: 5.55s\n",
      "620:\tlearn: 1.0000000\ttotal: 9.07s\tremaining: 5.54s\n",
      "621:\tlearn: 1.0000000\ttotal: 9.09s\tremaining: 5.52s\n",
      "622:\tlearn: 1.0000000\ttotal: 9.1s\tremaining: 5.51s\n",
      "623:\tlearn: 1.0000000\ttotal: 9.12s\tremaining: 5.5s\n",
      "624:\tlearn: 1.0000000\ttotal: 9.14s\tremaining: 5.48s\n",
      "625:\tlearn: 1.0000000\ttotal: 9.16s\tremaining: 5.47s\n",
      "626:\tlearn: 1.0000000\ttotal: 9.17s\tremaining: 5.46s\n",
      "627:\tlearn: 1.0000000\ttotal: 9.19s\tremaining: 5.44s\n",
      "628:\tlearn: 1.0000000\ttotal: 9.21s\tremaining: 5.43s\n",
      "629:\tlearn: 1.0000000\ttotal: 9.24s\tremaining: 5.42s\n",
      "630:\tlearn: 1.0000000\ttotal: 9.26s\tremaining: 5.41s\n",
      "631:\tlearn: 1.0000000\ttotal: 9.27s\tremaining: 5.4s\n",
      "632:\tlearn: 1.0000000\ttotal: 9.28s\tremaining: 5.38s\n",
      "633:\tlearn: 1.0000000\ttotal: 9.3s\tremaining: 5.37s\n",
      "634:\tlearn: 1.0000000\ttotal: 9.32s\tremaining: 5.36s\n",
      "635:\tlearn: 1.0000000\ttotal: 9.33s\tremaining: 5.34s\n",
      "636:\tlearn: 1.0000000\ttotal: 9.35s\tremaining: 5.33s\n",
      "637:\tlearn: 1.0000000\ttotal: 9.36s\tremaining: 5.31s\n",
      "638:\tlearn: 1.0000000\ttotal: 9.38s\tremaining: 5.3s\n",
      "639:\tlearn: 1.0000000\ttotal: 9.39s\tremaining: 5.28s\n",
      "640:\tlearn: 1.0000000\ttotal: 9.41s\tremaining: 5.27s\n",
      "641:\tlearn: 1.0000000\ttotal: 9.42s\tremaining: 5.25s\n",
      "642:\tlearn: 1.0000000\ttotal: 9.44s\tremaining: 5.24s\n",
      "643:\tlearn: 1.0000000\ttotal: 9.46s\tremaining: 5.23s\n",
      "644:\tlearn: 1.0000000\ttotal: 9.47s\tremaining: 5.21s\n",
      "645:\tlearn: 1.0000000\ttotal: 9.49s\tremaining: 5.2s\n",
      "646:\tlearn: 1.0000000\ttotal: 9.5s\tremaining: 5.18s\n",
      "647:\tlearn: 1.0000000\ttotal: 9.52s\tremaining: 5.17s\n",
      "648:\tlearn: 1.0000000\ttotal: 9.53s\tremaining: 5.16s\n",
      "649:\tlearn: 1.0000000\ttotal: 9.54s\tremaining: 5.14s\n",
      "650:\tlearn: 1.0000000\ttotal: 9.56s\tremaining: 5.12s\n",
      "651:\tlearn: 1.0000000\ttotal: 9.57s\tremaining: 5.11s\n",
      "652:\tlearn: 1.0000000\ttotal: 9.59s\tremaining: 5.09s\n",
      "653:\tlearn: 1.0000000\ttotal: 9.6s\tremaining: 5.08s\n",
      "654:\tlearn: 1.0000000\ttotal: 9.61s\tremaining: 5.06s\n",
      "655:\tlearn: 1.0000000\ttotal: 9.63s\tremaining: 5.05s\n",
      "656:\tlearn: 1.0000000\ttotal: 9.64s\tremaining: 5.03s\n",
      "657:\tlearn: 1.0000000\ttotal: 9.65s\tremaining: 5.02s\n",
      "658:\tlearn: 1.0000000\ttotal: 9.66s\tremaining: 5s\n",
      "659:\tlearn: 1.0000000\ttotal: 9.68s\tremaining: 4.99s\n",
      "660:\tlearn: 1.0000000\ttotal: 9.69s\tremaining: 4.97s\n",
      "661:\tlearn: 1.0000000\ttotal: 9.7s\tremaining: 4.95s\n",
      "662:\tlearn: 1.0000000\ttotal: 9.71s\tremaining: 4.94s\n",
      "663:\tlearn: 1.0000000\ttotal: 9.73s\tremaining: 4.92s\n",
      "664:\tlearn: 1.0000000\ttotal: 9.74s\tremaining: 4.91s\n",
      "665:\tlearn: 1.0000000\ttotal: 9.75s\tremaining: 4.89s\n",
      "666:\tlearn: 1.0000000\ttotal: 9.77s\tremaining: 4.88s\n",
      "667:\tlearn: 1.0000000\ttotal: 9.78s\tremaining: 4.86s\n",
      "668:\tlearn: 1.0000000\ttotal: 9.79s\tremaining: 4.85s\n",
      "669:\tlearn: 1.0000000\ttotal: 9.81s\tremaining: 4.83s\n",
      "670:\tlearn: 1.0000000\ttotal: 9.82s\tremaining: 4.82s\n",
      "671:\tlearn: 1.0000000\ttotal: 9.84s\tremaining: 4.8s\n",
      "672:\tlearn: 1.0000000\ttotal: 9.85s\tremaining: 4.79s\n",
      "673:\tlearn: 1.0000000\ttotal: 9.87s\tremaining: 4.77s\n",
      "674:\tlearn: 1.0000000\ttotal: 9.88s\tremaining: 4.76s\n",
      "675:\tlearn: 1.0000000\ttotal: 9.89s\tremaining: 4.74s\n",
      "676:\tlearn: 1.0000000\ttotal: 9.9s\tremaining: 4.72s\n",
      "677:\tlearn: 1.0000000\ttotal: 9.92s\tremaining: 4.71s\n",
      "678:\tlearn: 1.0000000\ttotal: 9.93s\tremaining: 4.7s\n",
      "679:\tlearn: 1.0000000\ttotal: 9.95s\tremaining: 4.68s\n",
      "680:\tlearn: 1.0000000\ttotal: 9.96s\tremaining: 4.66s\n",
      "681:\tlearn: 1.0000000\ttotal: 9.97s\tremaining: 4.65s\n",
      "682:\tlearn: 1.0000000\ttotal: 9.99s\tremaining: 4.64s\n",
      "683:\tlearn: 1.0000000\ttotal: 10s\tremaining: 4.62s\n",
      "684:\tlearn: 1.0000000\ttotal: 10s\tremaining: 4.61s\n",
      "685:\tlearn: 1.0000000\ttotal: 10s\tremaining: 4.59s\n",
      "686:\tlearn: 1.0000000\ttotal: 10s\tremaining: 4.58s\n",
      "687:\tlearn: 1.0000000\ttotal: 10.1s\tremaining: 4.56s\n",
      "688:\tlearn: 1.0000000\ttotal: 10.1s\tremaining: 4.55s\n",
      "689:\tlearn: 1.0000000\ttotal: 10.1s\tremaining: 4.53s\n",
      "690:\tlearn: 1.0000000\ttotal: 10.1s\tremaining: 4.52s\n",
      "691:\tlearn: 1.0000000\ttotal: 10.1s\tremaining: 4.5s\n",
      "692:\tlearn: 1.0000000\ttotal: 10.1s\tremaining: 4.49s\n",
      "693:\tlearn: 1.0000000\ttotal: 10.1s\tremaining: 4.47s\n",
      "694:\tlearn: 1.0000000\ttotal: 10.2s\tremaining: 4.46s\n",
      "695:\tlearn: 1.0000000\ttotal: 10.2s\tremaining: 4.44s\n",
      "696:\tlearn: 1.0000000\ttotal: 10.2s\tremaining: 4.43s\n",
      "697:\tlearn: 1.0000000\ttotal: 10.2s\tremaining: 4.42s\n",
      "698:\tlearn: 1.0000000\ttotal: 10.2s\tremaining: 4.4s\n",
      "699:\tlearn: 1.0000000\ttotal: 10.2s\tremaining: 4.39s\n",
      "700:\tlearn: 1.0000000\ttotal: 10.3s\tremaining: 4.37s\n",
      "701:\tlearn: 1.0000000\ttotal: 10.3s\tremaining: 4.36s\n",
      "702:\tlearn: 1.0000000\ttotal: 10.3s\tremaining: 4.34s\n",
      "703:\tlearn: 1.0000000\ttotal: 10.3s\tremaining: 4.33s\n",
      "704:\tlearn: 1.0000000\ttotal: 10.3s\tremaining: 4.31s\n",
      "705:\tlearn: 1.0000000\ttotal: 10.3s\tremaining: 4.3s\n",
      "706:\tlearn: 1.0000000\ttotal: 10.3s\tremaining: 4.28s\n",
      "707:\tlearn: 1.0000000\ttotal: 10.3s\tremaining: 4.27s\n",
      "708:\tlearn: 1.0000000\ttotal: 10.4s\tremaining: 4.25s\n",
      "709:\tlearn: 1.0000000\ttotal: 10.4s\tremaining: 4.24s\n",
      "710:\tlearn: 1.0000000\ttotal: 10.4s\tremaining: 4.22s\n",
      "711:\tlearn: 1.0000000\ttotal: 10.4s\tremaining: 4.21s\n",
      "712:\tlearn: 1.0000000\ttotal: 10.4s\tremaining: 4.19s\n",
      "713:\tlearn: 1.0000000\ttotal: 10.4s\tremaining: 4.18s\n",
      "714:\tlearn: 1.0000000\ttotal: 10.4s\tremaining: 4.16s\n",
      "715:\tlearn: 1.0000000\ttotal: 10.5s\tremaining: 4.15s\n",
      "716:\tlearn: 1.0000000\ttotal: 10.5s\tremaining: 4.13s\n",
      "717:\tlearn: 1.0000000\ttotal: 10.5s\tremaining: 4.12s\n",
      "718:\tlearn: 1.0000000\ttotal: 10.5s\tremaining: 4.11s\n",
      "719:\tlearn: 1.0000000\ttotal: 10.5s\tremaining: 4.09s\n",
      "720:\tlearn: 1.0000000\ttotal: 10.5s\tremaining: 4.08s\n",
      "721:\tlearn: 1.0000000\ttotal: 10.5s\tremaining: 4.06s\n",
      "722:\tlearn: 1.0000000\ttotal: 10.6s\tremaining: 4.05s\n",
      "723:\tlearn: 1.0000000\ttotal: 10.6s\tremaining: 4.03s\n",
      "724:\tlearn: 1.0000000\ttotal: 10.6s\tremaining: 4.02s\n",
      "725:\tlearn: 1.0000000\ttotal: 10.6s\tremaining: 4s\n",
      "726:\tlearn: 1.0000000\ttotal: 10.6s\tremaining: 3.99s\n",
      "727:\tlearn: 1.0000000\ttotal: 10.6s\tremaining: 3.97s\n",
      "728:\tlearn: 1.0000000\ttotal: 10.6s\tremaining: 3.96s\n",
      "729:\tlearn: 1.0000000\ttotal: 10.7s\tremaining: 3.94s\n",
      "730:\tlearn: 1.0000000\ttotal: 10.7s\tremaining: 3.93s\n",
      "731:\tlearn: 1.0000000\ttotal: 10.7s\tremaining: 3.91s\n",
      "732:\tlearn: 1.0000000\ttotal: 10.7s\tremaining: 3.9s\n",
      "733:\tlearn: 1.0000000\ttotal: 10.7s\tremaining: 3.88s\n",
      "734:\tlearn: 1.0000000\ttotal: 10.7s\tremaining: 3.87s\n",
      "735:\tlearn: 1.0000000\ttotal: 10.7s\tremaining: 3.85s\n",
      "736:\tlearn: 1.0000000\ttotal: 10.8s\tremaining: 3.84s\n",
      "737:\tlearn: 1.0000000\ttotal: 10.8s\tremaining: 3.82s\n",
      "738:\tlearn: 1.0000000\ttotal: 10.8s\tremaining: 3.81s\n",
      "739:\tlearn: 1.0000000\ttotal: 10.8s\tremaining: 3.79s\n",
      "740:\tlearn: 1.0000000\ttotal: 10.8s\tremaining: 3.78s\n",
      "741:\tlearn: 1.0000000\ttotal: 10.8s\tremaining: 3.77s\n",
      "742:\tlearn: 1.0000000\ttotal: 10.8s\tremaining: 3.75s\n",
      "743:\tlearn: 1.0000000\ttotal: 10.9s\tremaining: 3.74s\n",
      "744:\tlearn: 1.0000000\ttotal: 10.9s\tremaining: 3.73s\n",
      "745:\tlearn: 1.0000000\ttotal: 10.9s\tremaining: 3.71s\n",
      "746:\tlearn: 1.0000000\ttotal: 10.9s\tremaining: 3.7s\n",
      "747:\tlearn: 1.0000000\ttotal: 11s\tremaining: 3.69s\n",
      "748:\tlearn: 1.0000000\ttotal: 11s\tremaining: 3.68s\n",
      "749:\tlearn: 1.0000000\ttotal: 11s\tremaining: 3.66s\n",
      "750:\tlearn: 1.0000000\ttotal: 11s\tremaining: 3.65s\n",
      "751:\tlearn: 1.0000000\ttotal: 11s\tremaining: 3.64s\n",
      "752:\tlearn: 1.0000000\ttotal: 11s\tremaining: 3.62s\n",
      "753:\tlearn: 1.0000000\ttotal: 11.1s\tremaining: 3.61s\n",
      "754:\tlearn: 1.0000000\ttotal: 11.1s\tremaining: 3.6s\n",
      "755:\tlearn: 1.0000000\ttotal: 11.1s\tremaining: 3.58s\n",
      "756:\tlearn: 1.0000000\ttotal: 11.1s\tremaining: 3.57s\n",
      "757:\tlearn: 1.0000000\ttotal: 11.2s\tremaining: 3.56s\n",
      "758:\tlearn: 1.0000000\ttotal: 11.2s\tremaining: 3.55s\n",
      "759:\tlearn: 1.0000000\ttotal: 11.2s\tremaining: 3.54s\n",
      "760:\tlearn: 1.0000000\ttotal: 11.2s\tremaining: 3.52s\n",
      "761:\tlearn: 1.0000000\ttotal: 11.3s\tremaining: 3.51s\n",
      "762:\tlearn: 1.0000000\ttotal: 11.3s\tremaining: 3.5s\n",
      "763:\tlearn: 1.0000000\ttotal: 11.3s\tremaining: 3.49s\n",
      "764:\tlearn: 1.0000000\ttotal: 11.3s\tremaining: 3.48s\n",
      "765:\tlearn: 1.0000000\ttotal: 11.3s\tremaining: 3.46s\n",
      "766:\tlearn: 1.0000000\ttotal: 11.4s\tremaining: 3.45s\n",
      "767:\tlearn: 1.0000000\ttotal: 11.4s\tremaining: 3.44s\n",
      "768:\tlearn: 1.0000000\ttotal: 11.4s\tremaining: 3.42s\n",
      "769:\tlearn: 1.0000000\ttotal: 11.4s\tremaining: 3.41s\n",
      "770:\tlearn: 1.0000000\ttotal: 11.4s\tremaining: 3.4s\n",
      "771:\tlearn: 1.0000000\ttotal: 11.5s\tremaining: 3.38s\n",
      "772:\tlearn: 1.0000000\ttotal: 11.5s\tremaining: 3.37s\n",
      "773:\tlearn: 1.0000000\ttotal: 11.5s\tremaining: 3.35s\n",
      "774:\tlearn: 1.0000000\ttotal: 11.5s\tremaining: 3.35s\n",
      "775:\tlearn: 1.0000000\ttotal: 11.6s\tremaining: 3.34s\n",
      "776:\tlearn: 1.0000000\ttotal: 11.6s\tremaining: 3.33s\n",
      "777:\tlearn: 1.0000000\ttotal: 11.6s\tremaining: 3.31s\n",
      "778:\tlearn: 1.0000000\ttotal: 11.6s\tremaining: 3.3s\n",
      "779:\tlearn: 1.0000000\ttotal: 11.7s\tremaining: 3.29s\n",
      "780:\tlearn: 1.0000000\ttotal: 11.7s\tremaining: 3.27s\n",
      "781:\tlearn: 1.0000000\ttotal: 11.7s\tremaining: 3.26s\n",
      "782:\tlearn: 1.0000000\ttotal: 11.7s\tremaining: 3.24s\n",
      "783:\tlearn: 1.0000000\ttotal: 11.7s\tremaining: 3.23s\n",
      "784:\tlearn: 1.0000000\ttotal: 11.8s\tremaining: 3.22s\n",
      "785:\tlearn: 1.0000000\ttotal: 11.8s\tremaining: 3.21s\n",
      "786:\tlearn: 1.0000000\ttotal: 11.8s\tremaining: 3.19s\n",
      "787:\tlearn: 1.0000000\ttotal: 11.8s\tremaining: 3.18s\n",
      "788:\tlearn: 1.0000000\ttotal: 11.8s\tremaining: 3.17s\n",
      "789:\tlearn: 1.0000000\ttotal: 11.9s\tremaining: 3.15s\n",
      "790:\tlearn: 1.0000000\ttotal: 11.9s\tremaining: 3.14s\n",
      "791:\tlearn: 1.0000000\ttotal: 11.9s\tremaining: 3.13s\n",
      "792:\tlearn: 1.0000000\ttotal: 11.9s\tremaining: 3.11s\n",
      "793:\tlearn: 1.0000000\ttotal: 12s\tremaining: 3.1s\n",
      "794:\tlearn: 1.0000000\ttotal: 12s\tremaining: 3.09s\n",
      "795:\tlearn: 1.0000000\ttotal: 12s\tremaining: 3.08s\n",
      "796:\tlearn: 1.0000000\ttotal: 12.1s\tremaining: 3.07s\n",
      "797:\tlearn: 1.0000000\ttotal: 12.1s\tremaining: 3.06s\n",
      "798:\tlearn: 1.0000000\ttotal: 12.1s\tremaining: 3.05s\n",
      "799:\tlearn: 1.0000000\ttotal: 12.1s\tremaining: 3.04s\n",
      "800:\tlearn: 1.0000000\ttotal: 12.2s\tremaining: 3.02s\n",
      "801:\tlearn: 1.0000000\ttotal: 12.2s\tremaining: 3.01s\n",
      "802:\tlearn: 1.0000000\ttotal: 12.2s\tremaining: 3s\n",
      "803:\tlearn: 1.0000000\ttotal: 12.2s\tremaining: 2.98s\n",
      "804:\tlearn: 1.0000000\ttotal: 12.3s\tremaining: 2.97s\n",
      "805:\tlearn: 1.0000000\ttotal: 12.3s\tremaining: 2.96s\n",
      "806:\tlearn: 1.0000000\ttotal: 12.3s\tremaining: 2.94s\n",
      "807:\tlearn: 1.0000000\ttotal: 12.3s\tremaining: 2.93s\n",
      "808:\tlearn: 1.0000000\ttotal: 12.4s\tremaining: 2.92s\n",
      "809:\tlearn: 1.0000000\ttotal: 12.4s\tremaining: 2.9s\n",
      "810:\tlearn: 1.0000000\ttotal: 12.4s\tremaining: 2.89s\n",
      "811:\tlearn: 1.0000000\ttotal: 12.4s\tremaining: 2.87s\n",
      "812:\tlearn: 1.0000000\ttotal: 12.4s\tremaining: 2.86s\n",
      "813:\tlearn: 1.0000000\ttotal: 12.4s\tremaining: 2.84s\n",
      "814:\tlearn: 1.0000000\ttotal: 12.4s\tremaining: 2.82s\n",
      "815:\tlearn: 1.0000000\ttotal: 12.5s\tremaining: 2.81s\n",
      "816:\tlearn: 1.0000000\ttotal: 12.5s\tremaining: 2.79s\n",
      "817:\tlearn: 1.0000000\ttotal: 12.5s\tremaining: 2.78s\n",
      "818:\tlearn: 1.0000000\ttotal: 12.5s\tremaining: 2.76s\n",
      "819:\tlearn: 1.0000000\ttotal: 12.5s\tremaining: 2.75s\n",
      "820:\tlearn: 1.0000000\ttotal: 12.5s\tremaining: 2.73s\n",
      "821:\tlearn: 1.0000000\ttotal: 12.5s\tremaining: 2.72s\n",
      "822:\tlearn: 1.0000000\ttotal: 12.6s\tremaining: 2.7s\n",
      "823:\tlearn: 1.0000000\ttotal: 12.6s\tremaining: 2.69s\n",
      "824:\tlearn: 1.0000000\ttotal: 12.6s\tremaining: 2.67s\n",
      "825:\tlearn: 1.0000000\ttotal: 12.6s\tremaining: 2.65s\n",
      "826:\tlearn: 1.0000000\ttotal: 12.6s\tremaining: 2.64s\n",
      "827:\tlearn: 1.0000000\ttotal: 12.6s\tremaining: 2.62s\n",
      "828:\tlearn: 1.0000000\ttotal: 12.6s\tremaining: 2.61s\n",
      "829:\tlearn: 1.0000000\ttotal: 12.7s\tremaining: 2.59s\n",
      "830:\tlearn: 1.0000000\ttotal: 12.7s\tremaining: 2.58s\n",
      "831:\tlearn: 1.0000000\ttotal: 12.7s\tremaining: 2.56s\n",
      "832:\tlearn: 1.0000000\ttotal: 12.7s\tremaining: 2.55s\n",
      "833:\tlearn: 1.0000000\ttotal: 12.7s\tremaining: 2.53s\n",
      "834:\tlearn: 1.0000000\ttotal: 12.7s\tremaining: 2.52s\n",
      "835:\tlearn: 1.0000000\ttotal: 12.8s\tremaining: 2.5s\n",
      "836:\tlearn: 1.0000000\ttotal: 12.8s\tremaining: 2.49s\n",
      "837:\tlearn: 1.0000000\ttotal: 12.8s\tremaining: 2.47s\n",
      "838:\tlearn: 1.0000000\ttotal: 12.8s\tremaining: 2.46s\n",
      "839:\tlearn: 1.0000000\ttotal: 12.8s\tremaining: 2.44s\n",
      "840:\tlearn: 1.0000000\ttotal: 12.8s\tremaining: 2.43s\n",
      "841:\tlearn: 1.0000000\ttotal: 12.9s\tremaining: 2.41s\n",
      "842:\tlearn: 1.0000000\ttotal: 12.9s\tremaining: 2.4s\n",
      "843:\tlearn: 1.0000000\ttotal: 12.9s\tremaining: 2.38s\n",
      "844:\tlearn: 1.0000000\ttotal: 12.9s\tremaining: 2.37s\n",
      "845:\tlearn: 1.0000000\ttotal: 12.9s\tremaining: 2.35s\n",
      "846:\tlearn: 1.0000000\ttotal: 12.9s\tremaining: 2.34s\n",
      "847:\tlearn: 1.0000000\ttotal: 12.9s\tremaining: 2.32s\n",
      "848:\tlearn: 1.0000000\ttotal: 13s\tremaining: 2.3s\n",
      "849:\tlearn: 1.0000000\ttotal: 13s\tremaining: 2.29s\n",
      "850:\tlearn: 1.0000000\ttotal: 13s\tremaining: 2.27s\n",
      "851:\tlearn: 1.0000000\ttotal: 13s\tremaining: 2.26s\n",
      "852:\tlearn: 1.0000000\ttotal: 13s\tremaining: 2.24s\n",
      "853:\tlearn: 1.0000000\ttotal: 13s\tremaining: 2.23s\n",
      "854:\tlearn: 1.0000000\ttotal: 13s\tremaining: 2.21s\n",
      "855:\tlearn: 1.0000000\ttotal: 13.1s\tremaining: 2.19s\n",
      "856:\tlearn: 1.0000000\ttotal: 13.1s\tremaining: 2.18s\n",
      "857:\tlearn: 1.0000000\ttotal: 13.1s\tremaining: 2.16s\n",
      "858:\tlearn: 1.0000000\ttotal: 13.1s\tremaining: 2.15s\n",
      "859:\tlearn: 1.0000000\ttotal: 13.1s\tremaining: 2.13s\n",
      "860:\tlearn: 1.0000000\ttotal: 13.1s\tremaining: 2.12s\n",
      "861:\tlearn: 1.0000000\ttotal: 13.1s\tremaining: 2.1s\n",
      "862:\tlearn: 1.0000000\ttotal: 13.1s\tremaining: 2.09s\n",
      "863:\tlearn: 1.0000000\ttotal: 13.2s\tremaining: 2.07s\n",
      "864:\tlearn: 1.0000000\ttotal: 13.2s\tremaining: 2.06s\n",
      "865:\tlearn: 1.0000000\ttotal: 13.2s\tremaining: 2.04s\n",
      "866:\tlearn: 1.0000000\ttotal: 13.2s\tremaining: 2.02s\n",
      "867:\tlearn: 1.0000000\ttotal: 13.2s\tremaining: 2.01s\n",
      "868:\tlearn: 1.0000000\ttotal: 13.2s\tremaining: 2s\n",
      "869:\tlearn: 1.0000000\ttotal: 13.2s\tremaining: 1.98s\n",
      "870:\tlearn: 1.0000000\ttotal: 13.3s\tremaining: 1.96s\n",
      "871:\tlearn: 1.0000000\ttotal: 13.3s\tremaining: 1.95s\n",
      "872:\tlearn: 1.0000000\ttotal: 13.3s\tremaining: 1.93s\n",
      "873:\tlearn: 1.0000000\ttotal: 13.3s\tremaining: 1.92s\n",
      "874:\tlearn: 1.0000000\ttotal: 13.3s\tremaining: 1.9s\n",
      "875:\tlearn: 1.0000000\ttotal: 13.3s\tremaining: 1.89s\n",
      "876:\tlearn: 1.0000000\ttotal: 13.3s\tremaining: 1.87s\n",
      "877:\tlearn: 1.0000000\ttotal: 13.4s\tremaining: 1.85s\n",
      "878:\tlearn: 1.0000000\ttotal: 13.4s\tremaining: 1.84s\n",
      "879:\tlearn: 1.0000000\ttotal: 13.4s\tremaining: 1.82s\n",
      "880:\tlearn: 1.0000000\ttotal: 13.4s\tremaining: 1.81s\n",
      "881:\tlearn: 1.0000000\ttotal: 13.4s\tremaining: 1.79s\n",
      "882:\tlearn: 1.0000000\ttotal: 13.4s\tremaining: 1.78s\n",
      "883:\tlearn: 1.0000000\ttotal: 13.4s\tremaining: 1.76s\n",
      "884:\tlearn: 1.0000000\ttotal: 13.4s\tremaining: 1.75s\n",
      "885:\tlearn: 1.0000000\ttotal: 13.5s\tremaining: 1.73s\n",
      "886:\tlearn: 1.0000000\ttotal: 13.5s\tremaining: 1.72s\n",
      "887:\tlearn: 1.0000000\ttotal: 13.5s\tremaining: 1.7s\n",
      "888:\tlearn: 1.0000000\ttotal: 13.5s\tremaining: 1.69s\n",
      "889:\tlearn: 1.0000000\ttotal: 13.5s\tremaining: 1.67s\n",
      "890:\tlearn: 1.0000000\ttotal: 13.5s\tremaining: 1.65s\n",
      "891:\tlearn: 1.0000000\ttotal: 13.5s\tremaining: 1.64s\n",
      "892:\tlearn: 1.0000000\ttotal: 13.6s\tremaining: 1.62s\n",
      "893:\tlearn: 1.0000000\ttotal: 13.6s\tremaining: 1.61s\n",
      "894:\tlearn: 1.0000000\ttotal: 13.6s\tremaining: 1.59s\n",
      "895:\tlearn: 1.0000000\ttotal: 13.6s\tremaining: 1.58s\n",
      "896:\tlearn: 1.0000000\ttotal: 13.6s\tremaining: 1.56s\n",
      "897:\tlearn: 1.0000000\ttotal: 13.6s\tremaining: 1.55s\n",
      "898:\tlearn: 1.0000000\ttotal: 13.6s\tremaining: 1.53s\n",
      "899:\tlearn: 1.0000000\ttotal: 13.6s\tremaining: 1.51s\n",
      "900:\tlearn: 1.0000000\ttotal: 13.7s\tremaining: 1.5s\n",
      "901:\tlearn: 1.0000000\ttotal: 13.7s\tremaining: 1.48s\n",
      "902:\tlearn: 1.0000000\ttotal: 13.7s\tremaining: 1.47s\n",
      "903:\tlearn: 1.0000000\ttotal: 13.7s\tremaining: 1.45s\n",
      "904:\tlearn: 1.0000000\ttotal: 13.7s\tremaining: 1.44s\n",
      "905:\tlearn: 1.0000000\ttotal: 13.7s\tremaining: 1.42s\n",
      "906:\tlearn: 1.0000000\ttotal: 13.7s\tremaining: 1.41s\n",
      "907:\tlearn: 1.0000000\ttotal: 13.7s\tremaining: 1.39s\n",
      "908:\tlearn: 1.0000000\ttotal: 13.8s\tremaining: 1.38s\n",
      "909:\tlearn: 1.0000000\ttotal: 13.8s\tremaining: 1.36s\n",
      "910:\tlearn: 1.0000000\ttotal: 13.8s\tremaining: 1.35s\n",
      "911:\tlearn: 1.0000000\ttotal: 13.8s\tremaining: 1.33s\n",
      "912:\tlearn: 1.0000000\ttotal: 13.8s\tremaining: 1.31s\n",
      "913:\tlearn: 1.0000000\ttotal: 13.8s\tremaining: 1.3s\n",
      "914:\tlearn: 1.0000000\ttotal: 13.8s\tremaining: 1.28s\n",
      "915:\tlearn: 1.0000000\ttotal: 13.8s\tremaining: 1.27s\n",
      "916:\tlearn: 1.0000000\ttotal: 13.9s\tremaining: 1.25s\n",
      "917:\tlearn: 1.0000000\ttotal: 13.9s\tremaining: 1.24s\n",
      "918:\tlearn: 1.0000000\ttotal: 13.9s\tremaining: 1.22s\n",
      "919:\tlearn: 1.0000000\ttotal: 13.9s\tremaining: 1.21s\n",
      "920:\tlearn: 1.0000000\ttotal: 13.9s\tremaining: 1.19s\n",
      "921:\tlearn: 1.0000000\ttotal: 13.9s\tremaining: 1.18s\n",
      "922:\tlearn: 1.0000000\ttotal: 13.9s\tremaining: 1.16s\n",
      "923:\tlearn: 1.0000000\ttotal: 13.9s\tremaining: 1.15s\n",
      "924:\tlearn: 1.0000000\ttotal: 14s\tremaining: 1.13s\n",
      "925:\tlearn: 1.0000000\ttotal: 14s\tremaining: 1.12s\n",
      "926:\tlearn: 1.0000000\ttotal: 14s\tremaining: 1.1s\n",
      "927:\tlearn: 1.0000000\ttotal: 14s\tremaining: 1.09s\n",
      "928:\tlearn: 1.0000000\ttotal: 14s\tremaining: 1.07s\n",
      "929:\tlearn: 1.0000000\ttotal: 14s\tremaining: 1.06s\n",
      "930:\tlearn: 1.0000000\ttotal: 14s\tremaining: 1.04s\n",
      "931:\tlearn: 1.0000000\ttotal: 14.1s\tremaining: 1.03s\n",
      "932:\tlearn: 1.0000000\ttotal: 14.1s\tremaining: 1.01s\n",
      "933:\tlearn: 1.0000000\ttotal: 14.1s\tremaining: 996ms\n",
      "934:\tlearn: 1.0000000\ttotal: 14.1s\tremaining: 981ms\n",
      "935:\tlearn: 1.0000000\ttotal: 14.1s\tremaining: 966ms\n",
      "936:\tlearn: 1.0000000\ttotal: 14.1s\tremaining: 951ms\n",
      "937:\tlearn: 1.0000000\ttotal: 14.2s\tremaining: 936ms\n",
      "938:\tlearn: 1.0000000\ttotal: 14.2s\tremaining: 921ms\n",
      "939:\tlearn: 1.0000000\ttotal: 14.2s\tremaining: 905ms\n",
      "940:\tlearn: 1.0000000\ttotal: 14.2s\tremaining: 890ms\n",
      "941:\tlearn: 1.0000000\ttotal: 14.2s\tremaining: 875ms\n",
      "942:\tlearn: 1.0000000\ttotal: 14.2s\tremaining: 860ms\n",
      "943:\tlearn: 1.0000000\ttotal: 14.2s\tremaining: 845ms\n",
      "944:\tlearn: 1.0000000\ttotal: 14.3s\tremaining: 830ms\n",
      "945:\tlearn: 1.0000000\ttotal: 14.3s\tremaining: 815ms\n",
      "946:\tlearn: 1.0000000\ttotal: 14.3s\tremaining: 800ms\n",
      "947:\tlearn: 1.0000000\ttotal: 14.3s\tremaining: 785ms\n",
      "948:\tlearn: 1.0000000\ttotal: 14.3s\tremaining: 770ms\n",
      "949:\tlearn: 1.0000000\ttotal: 14.3s\tremaining: 755ms\n",
      "950:\tlearn: 1.0000000\ttotal: 14.4s\tremaining: 740ms\n",
      "951:\tlearn: 1.0000000\ttotal: 14.4s\tremaining: 725ms\n",
      "952:\tlearn: 1.0000000\ttotal: 14.4s\tremaining: 709ms\n",
      "953:\tlearn: 1.0000000\ttotal: 14.4s\tremaining: 694ms\n",
      "954:\tlearn: 1.0000000\ttotal: 14.4s\tremaining: 679ms\n",
      "955:\tlearn: 1.0000000\ttotal: 14.4s\tremaining: 664ms\n",
      "956:\tlearn: 1.0000000\ttotal: 14.4s\tremaining: 649ms\n",
      "957:\tlearn: 1.0000000\ttotal: 14.5s\tremaining: 634ms\n",
      "958:\tlearn: 1.0000000\ttotal: 14.5s\tremaining: 619ms\n",
      "959:\tlearn: 1.0000000\ttotal: 14.5s\tremaining: 604ms\n",
      "960:\tlearn: 1.0000000\ttotal: 14.5s\tremaining: 589ms\n",
      "961:\tlearn: 1.0000000\ttotal: 14.5s\tremaining: 574ms\n",
      "962:\tlearn: 1.0000000\ttotal: 14.5s\tremaining: 558ms\n",
      "963:\tlearn: 1.0000000\ttotal: 14.6s\tremaining: 543ms\n",
      "964:\tlearn: 1.0000000\ttotal: 14.6s\tremaining: 529ms\n",
      "965:\tlearn: 1.0000000\ttotal: 14.6s\tremaining: 514ms\n",
      "966:\tlearn: 1.0000000\ttotal: 14.6s\tremaining: 499ms\n",
      "967:\tlearn: 1.0000000\ttotal: 14.6s\tremaining: 484ms\n",
      "968:\tlearn: 1.0000000\ttotal: 14.7s\tremaining: 469ms\n",
      "969:\tlearn: 1.0000000\ttotal: 14.7s\tremaining: 454ms\n",
      "970:\tlearn: 1.0000000\ttotal: 14.7s\tremaining: 439ms\n",
      "971:\tlearn: 1.0000000\ttotal: 14.7s\tremaining: 424ms\n",
      "972:\tlearn: 1.0000000\ttotal: 14.7s\tremaining: 408ms\n",
      "973:\tlearn: 1.0000000\ttotal: 14.7s\tremaining: 393ms\n",
      "974:\tlearn: 1.0000000\ttotal: 14.7s\tremaining: 378ms\n",
      "975:\tlearn: 1.0000000\ttotal: 14.8s\tremaining: 363ms\n",
      "976:\tlearn: 1.0000000\ttotal: 14.8s\tremaining: 348ms\n",
      "977:\tlearn: 1.0000000\ttotal: 14.8s\tremaining: 333ms\n",
      "978:\tlearn: 1.0000000\ttotal: 14.8s\tremaining: 318ms\n",
      "979:\tlearn: 1.0000000\ttotal: 14.8s\tremaining: 302ms\n",
      "980:\tlearn: 1.0000000\ttotal: 14.8s\tremaining: 287ms\n",
      "981:\tlearn: 1.0000000\ttotal: 14.9s\tremaining: 272ms\n",
      "982:\tlearn: 1.0000000\ttotal: 14.9s\tremaining: 257ms\n",
      "983:\tlearn: 1.0000000\ttotal: 14.9s\tremaining: 242ms\n",
      "984:\tlearn: 1.0000000\ttotal: 14.9s\tremaining: 227ms\n",
      "985:\tlearn: 1.0000000\ttotal: 14.9s\tremaining: 212ms\n",
      "986:\tlearn: 1.0000000\ttotal: 14.9s\tremaining: 197ms\n",
      "987:\tlearn: 1.0000000\ttotal: 14.9s\tremaining: 181ms\n",
      "988:\tlearn: 1.0000000\ttotal: 15s\tremaining: 166ms\n",
      "989:\tlearn: 1.0000000\ttotal: 15s\tremaining: 151ms\n",
      "990:\tlearn: 1.0000000\ttotal: 15s\tremaining: 136ms\n",
      "991:\tlearn: 1.0000000\ttotal: 15s\tremaining: 121ms\n",
      "992:\tlearn: 1.0000000\ttotal: 15s\tremaining: 106ms\n",
      "993:\tlearn: 1.0000000\ttotal: 15s\tremaining: 90.7ms\n",
      "994:\tlearn: 1.0000000\ttotal: 15s\tremaining: 75.6ms\n",
      "995:\tlearn: 1.0000000\ttotal: 15.1s\tremaining: 60.5ms\n",
      "996:\tlearn: 1.0000000\ttotal: 15.1s\tremaining: 45.3ms\n",
      "997:\tlearn: 1.0000000\ttotal: 15.1s\tremaining: 30.2ms\n",
      "998:\tlearn: 1.0000000\ttotal: 15.1s\tremaining: 15.1ms\n",
      "999:\tlearn: 1.0000000\ttotal: 15.1s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fbf6b891be0>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model = CatBoostClassifier(depth=best_depth, learning_rate=best_learning_rate, l2_leaf_reg= best_l2, eval_metric='F1')\n",
    "cat_model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем нашу лучшую модель на тестовой выборке!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "print('F1 score:', f1_score(y_true=target_test, y_pred=cat_model.predict(features_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хороший результат!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Этот шаг был сделан отлично, молодец!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>ForestClassifier</th>\n",
       "      <th>CatboostClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1 score cross-val</th>\n",
       "      <td>0.96643</td>\n",
       "      <td>0.93287</td>\n",
       "      <td>0.98507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_params</th>\n",
       "      <td>No Params</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.93671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   LogisticRegression                       ForestClassifier  \\\n",
       "F1 score cross-val            0.96643                                0.93287   \n",
       "best_params                 No Params  {'max_depth': 5, 'n_estimators': 100}   \n",
       "Test                                -                                      -   \n",
       "\n",
       "                    CatboostClassifier  \n",
       "F1 score cross-val             0.98507  \n",
       "best_params                        NaN  \n",
       "Test                           0.93671  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = []\n",
    "test.append('-')\n",
    "test.append('-')\n",
    "test.append(round(0.9367088607594937, 5))\n",
    "\n",
    "final_pivot = []\n",
    "final_pivot.append(best_metrics)\n",
    "final_pivot.append(best_params)\n",
    "final_pivot.append(test)\n",
    "\n",
    "\n",
    "final = pd.DataFrame(final_pivot, columns=['LogisticRegression', 'ForestClassifier', 'CatboostClassifier'], index=['F1 score cross-val', 'best_params', 'Test'])\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном проекте была обучена модель на поиск токсичных твитов. Мы загрузили данные и проверили - они были чистыми и готовыми к обучению. В проекте мы воспользовались нейронной сетью BERT, но перед этим для корректной работы нам пришлось выкинуть из датасета слишком длинные твиты. Мы взяли 2000 случайных твитов и токенизировали их, не забыл создать маску внимания, после чего передали токены BERT и получили векторы, готовые к обучению! Мы обучили и проверили на кросс-валидации Логистическую Регрессию, Случайный Лес с гиперпараметрами и Catboost гиперпараметрами, где последняя показала себя лучше всего, выдав метрику на тестовой выборке F1 score: 0.9367088607594937!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Приятно видеть вывод в коцне проекта!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
