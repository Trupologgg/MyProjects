{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# HSE 2021: Mathematical Methods for Data Analysis\n",
    "\n",
    "## Homework 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Contents\n",
    "\n",
    "#### PCA, t-SNE – 4 points\n",
    "* [Task 1](#task1) (1.5 points)\n",
    "* [Task 2](#task2) (0.5 points)\n",
    "* [Task 3](#task3) (0.5 points)\n",
    "* [Task 4](#task3) (1 points)\n",
    "* [Task 5](#task4) (0.5 points)\n",
    "\n",
    "#### Clustering – 6 points\n",
    "* [Task 5](#task5) (1.5 points)\n",
    "* [Task 6](#task6) (1.5 points)\n",
    "* [Task 7](#task7) (1.5 points)\n",
    "* [Task 8](#task8) (0.5 point)\n",
    "* [Task 9](#task8) (1 point)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the file `data_Mar_64.txt`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "               0         1         2         3         4         5         6   \\\n0  Acer Campestre  0.003906  0.003906  0.027344  0.033203  0.007812  0.017578   \n1  Acer Campestre  0.005859  0.013672  0.027344  0.025391  0.013672  0.029297   \n2  Acer Campestre  0.011719  0.001953  0.027344  0.044922  0.017578  0.042969   \n3  Acer Campestre  0.013672  0.011719  0.037109  0.017578  0.011719  0.087891   \n4  Acer Campestre  0.007812  0.009766  0.027344  0.025391  0.001953  0.005859   \n\n         7         8         9   ...        55        56        57        58  \\\n0  0.023438  0.005859  0.000000  ...  0.011719  0.000000  0.005859  0.035156   \n1  0.019531  0.000000  0.001953  ...  0.017578  0.000000  0.021484  0.017578   \n2  0.023438  0.000000  0.003906  ...  0.035156  0.000000  0.015625  0.021484   \n3  0.023438  0.000000  0.000000  ...  0.015625  0.001953  0.021484  0.029297   \n4  0.015625  0.000000  0.005859  ...  0.023438  0.001953  0.021484  0.048828   \n\n         59        60        61        62        63   64  \n0  0.027344  0.033203  0.001953  0.000000  0.017578  0.0  \n1  0.046875  0.005859  0.003906  0.003906  0.046875  0.0  \n2  0.056641  0.009766  0.003906  0.000000  0.015625  0.0  \n3  0.033203  0.003906  0.000000  0.001953  0.027344  0.0  \n4  0.056641  0.019531  0.000000  0.000000  0.013672  0.0  \n\n[5 rows x 65 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>55</th>\n      <th>56</th>\n      <th>57</th>\n      <th>58</th>\n      <th>59</th>\n      <th>60</th>\n      <th>61</th>\n      <th>62</th>\n      <th>63</th>\n      <th>64</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Acer Campestre</td>\n      <td>0.003906</td>\n      <td>0.003906</td>\n      <td>0.027344</td>\n      <td>0.033203</td>\n      <td>0.007812</td>\n      <td>0.017578</td>\n      <td>0.023438</td>\n      <td>0.005859</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.011719</td>\n      <td>0.000000</td>\n      <td>0.005859</td>\n      <td>0.035156</td>\n      <td>0.027344</td>\n      <td>0.033203</td>\n      <td>0.001953</td>\n      <td>0.000000</td>\n      <td>0.017578</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Acer Campestre</td>\n      <td>0.005859</td>\n      <td>0.013672</td>\n      <td>0.027344</td>\n      <td>0.025391</td>\n      <td>0.013672</td>\n      <td>0.029297</td>\n      <td>0.019531</td>\n      <td>0.000000</td>\n      <td>0.001953</td>\n      <td>...</td>\n      <td>0.017578</td>\n      <td>0.000000</td>\n      <td>0.021484</td>\n      <td>0.017578</td>\n      <td>0.046875</td>\n      <td>0.005859</td>\n      <td>0.003906</td>\n      <td>0.003906</td>\n      <td>0.046875</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Acer Campestre</td>\n      <td>0.011719</td>\n      <td>0.001953</td>\n      <td>0.027344</td>\n      <td>0.044922</td>\n      <td>0.017578</td>\n      <td>0.042969</td>\n      <td>0.023438</td>\n      <td>0.000000</td>\n      <td>0.003906</td>\n      <td>...</td>\n      <td>0.035156</td>\n      <td>0.000000</td>\n      <td>0.015625</td>\n      <td>0.021484</td>\n      <td>0.056641</td>\n      <td>0.009766</td>\n      <td>0.003906</td>\n      <td>0.000000</td>\n      <td>0.015625</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Acer Campestre</td>\n      <td>0.013672</td>\n      <td>0.011719</td>\n      <td>0.037109</td>\n      <td>0.017578</td>\n      <td>0.011719</td>\n      <td>0.087891</td>\n      <td>0.023438</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.015625</td>\n      <td>0.001953</td>\n      <td>0.021484</td>\n      <td>0.029297</td>\n      <td>0.033203</td>\n      <td>0.003906</td>\n      <td>0.000000</td>\n      <td>0.001953</td>\n      <td>0.027344</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Acer Campestre</td>\n      <td>0.007812</td>\n      <td>0.009766</td>\n      <td>0.027344</td>\n      <td>0.025391</td>\n      <td>0.001953</td>\n      <td>0.005859</td>\n      <td>0.015625</td>\n      <td>0.000000</td>\n      <td>0.005859</td>\n      <td>...</td>\n      <td>0.023438</td>\n      <td>0.001953</td>\n      <td>0.021484</td>\n      <td>0.048828</td>\n      <td>0.056641</td>\n      <td>0.019531</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.013672</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 65 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../datasets/data_Mar_64.txt', header=None)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This [dataset](https://archive.ics.uci.edu/ml/datasets/One-hundred+plant+species+leaves+data+set) consists of work carried out by James Cope, Charles Mallah, and James Orwell, Kingston University London. The Leaves were collected in the Royal Botanic Gardens, Kew, UK.\n",
    "\n",
    "For Each feature, a 64 element vector is given per sample of leaf. One file for each 64-element feature vectors. **Each row begins with the class label**. Here is the plant leaf **classification task**. The remaining 64 elements is the feature vector."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "(1600, 65)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sixteen samples of leaf each of one-hundred plant species\n",
    "data.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The first column is the target, put it in a separate variable."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X, y_name = np.array(data.iloc[:, 1:]), data.iloc[:, 0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 1. <a id=\"task1\"></a> (1.5 points)** Let's do the following pipeline (detailed instructions will be in next cells)\n",
    "\n",
    "- Encode your textual target.\n",
    "- Split your data into train and test. Train a simple classification model without any improvements and calculate metrics.\n",
    "- Then let's look at the low dimensional representations of the features and look at the classes there. We will use linear method PCA and non-linear t-SNE (t-distributed stochastic neighbor embedding). In this task we learn how to visualize data at the low dimensional space and check whether the obtained points are separable or not."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The target variable takes a text value. Use the `LabelEncoder` from `sklearn` to encode the text variable `y_name` and save the resulting values to the variable `y`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "## your code here\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split your data into **train** and **test** in proportion 1:4."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "## your code here\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(X, y, test_size=0.25, random_state=12345)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train SVM with linear kernel on your data to predict target. Calculate accuracy, F-score."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'c'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m## your code here\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msvm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SVC\n\u001B[1;32m----> 5\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mSVC\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkernel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlinear\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m12345\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(features_train, target_train)\n\u001B[0;32m      7\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m accuracy_score(y_true\u001B[38;5;241m=\u001B[39mtarget_test, y_pred\u001B[38;5;241m=\u001B[39mmodel\u001B[38;5;241m.\u001B[39mpredict(features_test))\n",
      "\u001B[1;31mTypeError\u001B[0m: __init__() got an unexpected keyword argument 'c'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "## your code here\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(kernel='linear', random_state=12345, c=100)\n",
    "model.fit(features_train, target_train)\n",
    "accuracy = accuracy_score(y_true=target_test, y_pred=model.predict(features_test))\n",
    "print(\"Accuracy:\", accuracy)\n",
    "f1 = f1_score(y_true=target_test, y_pred=model.predict(features_test), average='weighted')\n",
    "print(\"F1 score:\", f1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's try Principal Component Analysis. Use the `PCA` method from `sklearn.decomposiion` to reduce the dimension of the feature space to two. Fix `random_state=42`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## your code here\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2, random_state=42).fit_transform(X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Select objects that match values from 0 to 15 of the target variable `y`. Draw the selected objects in a two-dimensional feature space using the `scatter` method from `matplotlib.pyplot`. To display objects of different classes in different colors, pass `c = y[y<=15]` to the `scatter` method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "c = y[y <= 15]\n",
    "## your code here\n",
    "plt.scatter(pca[y < 16][:, 0], pca[y < 16][:, 1], c=c);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Do the same procedure as in two previous cells, but now for the `TSNE` method from `sklearn.manifold`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## your code here\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42).fit_transform(X)\n",
    "\n",
    "c = y[y <= 15]\n",
    "## your code here\n",
    "plt.scatter(tsne[y < 16][:, 0], tsne[y < 16][:, 1], c=c);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 2. <a id=\"task2\"></a> (0.5 points)** Specify the coordinates of the object with index 1 (`X[1]`) after applying the TSNE method. Round the numbers to hundredths."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## your code here\n",
    "\n",
    "cords_1_tsne = np.round(tsne[1], 2)\n",
    "cords_1_tsne"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 3. <a id=\"task3\"></a> (0.5 points)** Specify the coordinates of the object with index 1 (`X[1]`) after applying the PCA method. Round the numbers to hundredths."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## your code here\n",
    "\n",
    "cords_1_pca = np.round(pca[1], 2)\n",
    "cords_1_pca"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 4. <a id=\"task4\"></a> (1 points)** What conclusions can be drawn from the obtained images? Choose the right one(s).\n",
    "\n",
    "1) Using the principal components method, it was possible to visualize objects on a plane and objects of different classes are visually separable\n",
    "\n",
    "2) Using the TSNE method, it was possible to visualize objects on a plane and objects of different classes are visually separable\n",
    "\n",
    "3) Using the TSNE and PCA methods, it was possible to visualize objects on a plane and objects of different classes are visually separable\n",
    "\n",
    "4) Using the TSNE and PCA methods, it was possible to visualize objects on a plane and objects of different classes are not visually separable"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ответ: 2.\n",
    "Визуализация разделения только в TSNE."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 5. (0.5 points)** Again try to fit your simple classifier, this time using transformed data to two-dimensional space. To do it choose the best feature representation in your opinion from two existing. Did the metrics improve?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## your code here\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "## your code here\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "print(\"TSNE\")\n",
    "features_train, features_test, target_train, target_test = train_test_split(tsne, y, test_size=0.2, random_state=12345)\n",
    "\n",
    "model = SVC(kernel='linear', random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "accuracy = accuracy_score(y_true=target_test, y_pred=model.predict(features_test))\n",
    "print(\"Accuracy:\", accuracy)\n",
    "f1 = f1_score(y_true=target_test, y_pred=model.predict(features_test), average='weighted')\n",
    "print(\"F1 score:\", f1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## your code here\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "## your code here\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "print(\"PCA\")\n",
    "features_train, features_test, target_train, target_test = train_test_split(pca, y, test_size=0.25, random_state=12345)\n",
    "\n",
    "model = SVC(kernel='linear', random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "accuracy = accuracy_score(y_true=target_test, y_pred=model.predict(features_test))\n",
    "print(\"Accuracy:\", accuracy)\n",
    "f1 = f1_score(y_true=target_test, y_pred=model.predict(features_test), average='weighted')\n",
    "print(\"F1 score:\", f1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## K_means"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 6. <a id=\"task5\"></a> (1.5 points)** Implement the MyKMeans class.\n",
    "\n",
    "The class must match the template shown below. Please, add code where needed. Some guidelines are the following:\n",
    "\n",
    "The class constructor is passed to:\n",
    "- n_clusters - the number of clusters that the data will be split into\n",
    "\n",
    "- n_iters - the maximum number of iterations that can be done in this algorithm\n",
    "\n",
    "Realize `update_centers` and `update_labels` methods.\n",
    "\n",
    "\n",
    "In the `fit` method:\n",
    "\n",
    "- Write sequential call of `self_centers` and `self_labels`.\n",
    "\n",
    "then in the loop by the number of iterations you need to implement:\n",
    "- calculate the nearest cluster center for each object\n",
    "- recalculate the center of each cluster (the average of each of the coordinates of all objects assigned to this cluster)\n",
    "put the calculated new cluster centers in the `new_centers` variable\n",
    "\n",
    "In the `predict` method:\n",
    "\n",
    "the nearest cluster centers for `X` objects are calculated"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def plot_clust(X, centers, lables, ax):\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=lables)\n",
    "    ax.scatter(centers[:, 0], centers[:, 1], marker='>', color='red')\n",
    "\n",
    "\n",
    "class MyKMeans():\n",
    "    def __init__(self, n_clusters=3, n_iters=100, seed=None):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.labels = None\n",
    "        self.centers = None\n",
    "        self.n_iters = n_iters\n",
    "        self.seed = 0 if seed is None else seed\n",
    "        np.random.seed(self.seed)\n",
    "\n",
    "    def update_centers(self, X):\n",
    "        ## your code here\n",
    "        tmp_uniq = np.unique(self.labels)\n",
    "        # summ = 0\n",
    "        centers = []\n",
    "        for i in tmp_uniq:\n",
    "            centers.append(X[self.labels == i].mean(axis=0))\n",
    "        # centers = np.array(summ)\n",
    "        # for i in tmp_uniq:\n",
    "        #     if X[self.labels] == i:\n",
    "        #         centers[i] = np.array(X[self.labels == i].mean(axis=0))\n",
    "        # for i in tmp_uniq:\n",
    "        #\n",
    "        centers = np.array(centers)\n",
    "        return centers\n",
    "\n",
    "    def update_labels(self, X):\n",
    "        ## your code here\n",
    "        labels = pairwise_distances_argmin(X, self.centers)\n",
    "        return labels\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.centers = X[np.random.choice(len(X), self.n_clusters, replace=False)]\n",
    "        self.labels = self.update_labels(X)\n",
    "\n",
    "        for it in range(self.n_iters):\n",
    "            new_labels = self.update_labels(X)\n",
    "            self.labels = new_labels\n",
    "\n",
    "            new_centers = self.update_centers(X)\n",
    "            if np.allclose(self.centers.flatten(), new_centers.flatten(), atol=1e-1):\n",
    "                self.centers = new_centers\n",
    "                self.labels = new_labels\n",
    "                print('Converge by tolerance centers')\n",
    "\n",
    "                fig, ax = plt.subplots(1, 1)\n",
    "                plot_clust(X, new_centers, new_labels, ax)\n",
    "                return 0\n",
    "\n",
    "            self.centers = new_centers\n",
    "\n",
    "            fig, ax = plt.subplots(1, 1)\n",
    "            plot_clust(X, new_centers, new_labels, ax)\n",
    "            plt.pause(0.3);\n",
    "            clear_output(wait=True);\n",
    "\n",
    "        return 1\n",
    "\n",
    "    def predict(self, X):\n",
    "        labels = self.update_labels(X)\n",
    "        return labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generating data for clustering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "n_samples = 1000\n",
    "\n",
    "noisy_blobs = datasets.make_blobs(n_samples=n_samples,\n",
    "                                  cluster_std=[1.0, 0.5, 0.5],\n",
    "                                  random_state=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X, y = noisy_blobs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 7. <a id=\"task6\"></a> (1.5 points)**\n",
    "\n",
    "7.1 Cluster noisy_blobs objects with `MyKMeans`, use the hyperparameters `n_clusters=3`, `n_iters=3`. Plot result. Specify the result label for the object with index 0."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## your code here\n",
    "model = MyKMeans(n_iters=3)  #clasters default 3 in class\n",
    "model.fit(X)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Result label for the object with index 0'\n",
    "      f'\\n'\n",
    "      f'center of the {model.predict(X)[0]}st cluster: {model.update_centers(X)[0]}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "7.2 Cluster noisy_blobs objects, use the hyperparameters `n_clusters=3`, `n_iters = 100`. Plot result. Specify the result label for the object with index 0."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## your code here\n",
    "model = MyKMeans(n_iters=100)  #clasters default 3 in class\n",
    "model.fit(X)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Result label for the object with index 0'\n",
    "      f'\\n'\n",
    "      f'center of the {model.predict(X)[0]}st cluster: {model.update_centers(X)[0]}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "7.3 Calculate how many objects changed the label of the predicted cluster when changing the hyperparameter n_iters from 3 to 100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## your code here\n",
    "model3 = MyKMeans(n_iters=3)\n",
    "model3.fit(X)\n",
    "model100 = MyKMeans(n_iters=100)\n",
    "model100.fit(X)\n",
    "# print(len(model3.predict(X)[0]))\n",
    "print(model3.predict(X)[0])\n",
    "print(model100.predict(X)[0])\n",
    "# print(len(model3.predict(X)))\n",
    "num_of_changed = (model3.predict(X)[0] != model100.predict(X)[0]).sum()\n",
    "# num_of_changed = len(model3.predict(X)[0]) - num_of_changed\n",
    "num_of_changed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 8. <a id=\"task6\"></a> (1.5 points)**\n",
    "\n",
    "Using the elbow method, select the optimal number of clusters, show it on the plot. As a metric, use the sum of the squares of the distances between the data points and the centroids of the clusters assigned to them divided by number of clusters. To do this, iterate the parameter k from 2 to 50 in steps of 2."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "## your code here\n",
    "metrics_list = []\n",
    "for n_clusters in range(2, 51, 2):\n",
    "    model = MyKMeans(n_clusters=n_clusters)\n",
    "    model.fit(X)\n",
    "    # for i in np.unique(model.labels):\n",
    "    #     tmp = np.sum(pairwise_distances(X[model.labels == i], [model.centers[i]]) ** 2)\n",
    "    #     metrics_list.append(tmp)\n",
    "    tmp_sum = 0\n",
    "    for i in np.unique(model.labels):\n",
    "        tmp = np.sum(pairwise_distances(X[model.labels == i], [model.centers[i]]) ** 2)\n",
    "        tmp_sum += tmp\n",
    "    metrics_list.append(tmp_sum)\n",
    "\n",
    "print(len(metrics_list))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(range(2, 51, 2), metrics_list, label='depends')\n",
    "plt.xlabel('clusters')\n",
    "plt.ylabel('distances between')\n",
    "plt.legend(loc='right')\n",
    "plt.figure(figsize=(10, 15))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "\n",
    "## your code here\n",
    "metrics_list = []\n",
    "\n",
    "model = MyKMeans(n_clusters=15)\n",
    "model.fit(X)\n",
    "# for i in np.unique(model.labels):\n",
    "#     tmp = np.sum(pairwise_distances(X[model.labels == i], [model.centers[i]]) ** 2)\n",
    "#     metrics_list.append(tmp)\n",
    "# tmp_sum = 0\n",
    "# for i in np.unique(model.labels):\n",
    "#     tmp = np.sum(pairwise_distances(X[model.labels == i], [model.centers[i]]) ** 2)\n",
    "#     tmp_sum += tmp\n",
    "# metrics_list.append(tmp_sum)\n",
    "#\n",
    "# print(len(metrics_list))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DBSCAN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 9. <a id=\"task7\"></a> (0.5 points)** Cluster noisy_blobs objects using DBSCAN. Use the DBSCAN implementation from sklearn. Fix the `eps=0.3` hyperparameter. Plot result. Specify the response for the object with index 2."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "## your code here\n",
    "model = DBSCAN(eps=0.3)\n",
    "model.fit(X)\n",
    "predictions = model.fit_predict(X)\n",
    "\n",
    "for i in np.unique(y):\n",
    "    plt.scatter(X[predictions == i, 0], X[predictions == i, 1])\n",
    "print(predictions[2])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 10. <a id=\"task8\"></a> (1 point)**\n",
    "\n",
    "Try different settings of ```eps``` distances (from 0.1 to 0.5) and several values of your choice of ```min_samples```. For each setting plot results. Also output the number of clusters and outliers (objects marked as -1)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## your code here"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
