{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.applications.densenet import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date       Open       High        Low      Close  Adj Close  \\\n",
      "0  2018-01-16  22.502666  23.000000  22.320000  22.670668  22.670668   \n",
      "1  2018-01-17  22.698000  23.266666  22.650000  23.143999  23.143999   \n",
      "2  2018-01-18  23.044666  23.486668  22.916000  22.971333  22.971333   \n",
      "3  2018-01-19  23.000000  23.372667  22.840000  23.334667  23.334667   \n",
      "4  2018-01-22  23.293333  23.855333  23.280001  23.437332  23.437332   \n",
      "\n",
      "      Volume  \n",
      "0   97114500  \n",
      "1  106552500  \n",
      "2   85287000  \n",
      "3   73324500  \n",
      "4   93156000  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('../datasets/TSLA.csv')\n",
    "print(df.head()) #7 columns, including the Date."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1244   2022-12-22\n",
      "1245   2022-12-23\n",
      "1246   2022-12-27\n",
      "1247   2022-12-28\n",
      "1248   2022-12-29\n",
      "1249   2022-12-30\n",
      "1250   2023-01-03\n",
      "1251   2023-01-04\n",
      "1252   2023-01-05\n",
      "1253   2023-01-06\n",
      "1254   2023-01-09\n",
      "1255   2023-01-10\n",
      "1256   2023-01-11\n",
      "1257   2023-01-12\n",
      "1258   2023-01-13\n",
      "Name: Date, dtype: datetime64[ns]\n",
      "['Open', 'High', 'Low', 'Close', 'Adj Close']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Separate dates for future plotting\n",
    "train_dates = pd.to_datetime(df['Date'])\n",
    "print(train_dates.tail(15)) #Check last few dates.\n",
    "\n",
    "#Variables for training\n",
    "cols  = list(df)[1:6]\n",
    "#Date and volume columns are not used in training.\n",
    "print(cols) #['Open', 'High', 'Low', 'Close', 'Adj Close']\n",
    "\n",
    "#New dataframe with only training data - 5 columns\n",
    "df_for_training = df[cols].astype(float)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "\n",
    "# df_for_plot=df_for_training.tail(5000)\n",
    "# df_for_plot.plot.line()\n",
    "\n",
    "#LSTM uses sigmoid and tanh that are sensitive to magnitude so values need to be normalized\n",
    "# normalize the dataset\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(df_for_training)\n",
    "df_for_training_scaled = scaler.transform(df_for_training)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX shape == (1245, 14, 5).\n",
      "trainY shape == (1245, 1).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#As required for LSTM networks, we require to reshape an input data into n_samples x timesteps x n_features.\n",
    "#In this example, the n_features is 5. We will make timesteps = 14 (past days data used for training).\n",
    "\n",
    "#Empty lists to be populated using formatted training data\n",
    "trainX = []\n",
    "trainY = []\n",
    "\n",
    "n_future = 1   # Number of days we want to look into the future based on the past days.\n",
    "n_past = 14  # Number of past days we want to use to predict the future.\n",
    "\n",
    "#Reformat input data into a shape: (n_samples x timesteps x n_features)\n",
    "#In my example, my df_for_training_scaled has a shape (12823, 5)\n",
    "#12823 refers to the number of data points and 5 refers to the columns (multi-variables).\n",
    "for i in range(n_past, len(df_for_training_scaled) - n_future +1):\n",
    "    trainX.append(df_for_training_scaled[i - n_past:i, 0:df_for_training.shape[1]])\n",
    "    trainY.append(df_for_training_scaled[i + n_future - 1:i + n_future, 0])\n",
    "\n",
    "trainX, trainY = np.array(trainX), np.array(trainY)\n",
    "\n",
    "print('trainX shape == {}.'.format(trainX.shape))\n",
    "print('trainY shape == {}.'.format(trainY.shape))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "(245, 14, 5)"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX = trainX[1000:]\n",
    "testY = trainY[1000:]\n",
    "trainX = trainX[:1000]\n",
    "trainY = trainY[:1000]\n",
    "testX.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 14, 64)            17920     \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 32)                12416     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,369\n",
      "Trainable params: 30,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(32, activation='relu', return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(trainY.shape[1]))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "57/57 [==============================] - 2s 13ms/step - loss: 0.1522 - val_loss: 0.3208\n",
      "Epoch 2/5\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.0337 - val_loss: 0.0739\n",
      "Epoch 3/5\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.0276 - val_loss: 0.0490\n",
      "Epoch 4/5\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.0290 - val_loss: 0.1282\n",
      "Epoch 5/5\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.0225 - val_loss: 0.1721\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(trainX, trainY, epochs=5, batch_size=16, validation_split=0.1, verbose=1)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(testX)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (245,1) doesn't match the broadcast shape (245,5)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/47/4y0ypxc92dz4v_h0jyn8jqpw0000gn/T/ipykernel_74031/2666090405.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mpredictions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mscaler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minverse_transform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpredictions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mpredictions\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\u001B[0m in \u001B[0;36minverse_transform\u001B[0;34m(self, X, copy)\u001B[0m\n\u001B[1;32m   1033\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1034\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_std\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1035\u001B[0;31m                 \u001B[0mX\u001B[0m \u001B[0;34m*=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscale_\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1036\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_mean\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1037\u001B[0m                 \u001B[0mX\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean_\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: non-broadcastable output operand with shape (245,1) doesn't match the broadcast shape (245,5)"
     ]
    }
   ],
   "source": [
    "predictions = scaler.inverse_transform(predictions)\n",
    "predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
